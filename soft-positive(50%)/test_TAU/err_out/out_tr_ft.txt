/usr/bin:/bin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin
/home/wang9/anaconda3/envs/torch_1.11/bin:/usr/bin:/bin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin
{'debug': False, 'num_workers': 8, 'seed': 0, 'n_epochs': 100, 'batch_size': 64, 'ckp_path': '../checkpoint/', 'data_path': '../../../TAU-urban-audio-visual-scenes-2021-development/', 'video_clip_duration': 10, 'video_fps': 16.0, 'audio_fps': 16000, 'audio_dur': 10, 'spectrogram_fps': 100.0, 'n_fft': 512, 'n_mels': 64, 'model_type': 'audio', 'num_classes': 10, 'feat_name': 'pool', 'pooling_op': None, 'feat_dim': 512, 'use_dropout': True, 'dropout': 0.5}
use_cude True
model type is audio linear prob is False
Directory  ./audio_model_ft/  Created 
use_cude True
-----------start training
this is epoch 1
| epoch   1 |   100/  111 batches | ms/batch 922.58 | loss  1.41 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   1 | time: 99.18s | training loss  1.66 |
    | end of validation epoch   1 | time: 69.31s | validation loss  1.10 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 1 training loss is  [1.6638764282604595] validation loss is  [1.0953512836325292]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 2
| epoch   2 |   100/  111 batches | ms/batch 928.83 | loss  0.96 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   2 | time: 100.05s | training loss  1.13 |
    | end of validation epoch   2 | time: 68.63s | validation loss  1.02 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 2 training loss is  [1.6638764282604595, 1.1267886532319558] validation loss is  [1.0953512836325292, 1.019932325812988]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 3
| epoch   3 |   100/  111 batches | ms/batch 912.17 | loss  0.82 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   3 | time: 98.07s | training loss  0.97 |
    | end of validation epoch   3 | time: 63.60s | validation loss  0.93 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 3 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 4
| epoch   4 |   100/  111 batches | ms/batch 908.64 | loss  0.77 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   4 | time: 97.70s | training loss  0.82 |
    | end of validation epoch   4 | time: 63.46s | validation loss  0.99 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 4 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 5
| epoch   5 |   100/  111 batches | ms/batch 902.91 | loss  0.54 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   5 | time: 97.07s | training loss  0.77 |
    | end of validation epoch   5 | time: 63.72s | validation loss  1.07 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 5 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 6
| epoch   6 |   100/  111 batches | ms/batch 903.30 | loss  0.63 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   6 | time: 97.15s | training loss  0.67 |
    | end of validation epoch   6 | time: 63.57s | validation loss  0.98 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 6 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 7
| epoch   7 |   100/  111 batches | ms/batch 901.18 | loss  0.61 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   7 | time: 96.94s | training loss  0.62 |
    | end of validation epoch   7 | time: 63.64s | validation loss  0.98 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 7 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 8
| epoch   8 |   100/  111 batches | ms/batch 898.40 | loss  0.48 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   8 | time: 96.67s | training loss  0.56 |
    | end of validation epoch   8 | time: 63.74s | validation loss  1.04 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 8 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 9
| epoch   9 |   100/  111 batches | ms/batch 897.57 | loss  0.33 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   9 | time: 96.86s | training loss  0.50 |
    | end of validation epoch   9 | time: 63.72s | validation loss  1.05 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 9 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 10
| epoch  10 |   100/  111 batches | ms/batch 899.63 | loss  0.51 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  10 | time: 96.86s | training loss  0.46 |
    | end of validation epoch  10 | time: 63.57s | validation loss  1.05 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 10 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 11
| epoch  11 |   100/  111 batches | ms/batch 898.55 | loss  0.52 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  11 | time: 96.62s | training loss  0.43 |
    | end of validation epoch  11 | time: 63.62s | validation loss  1.19 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 11 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 12
| epoch  12 |   100/  111 batches | ms/batch 898.66 | loss  0.34 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  12 | time: 96.76s | training loss  0.41 |
    | end of validation epoch  12 | time: 63.85s | validation loss  1.00 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 12 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 13
| epoch  13 |   100/  111 batches | ms/batch 893.90 | loss  0.31 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  13 | time: 96.36s | training loss  0.37 |
    | end of validation epoch  13 | time: 63.43s | validation loss  0.96 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 13 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 14
| epoch  14 |   100/  111 batches | ms/batch 896.74 | loss  0.21 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  14 | time: 96.58s | training loss  0.35 |
    | end of validation epoch  14 | time: 63.44s | validation loss  1.12 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 14 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 15
| epoch  15 |   100/  111 batches | ms/batch 896.89 | loss  0.45 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  15 | time: 96.52s | training loss  0.35 |
    | end of validation epoch  15 | time: 63.88s | validation loss  1.10 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 15 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 16
| epoch  16 |   100/  111 batches | ms/batch 897.17 | loss  0.32 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  16 | time: 96.79s | training loss  0.32 |
    | end of validation epoch  16 | time: 63.67s | validation loss  1.16 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 16 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 17
| epoch  17 |   100/  111 batches | ms/batch 945.15 | loss  0.29 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  17 | time: 101.60s | training loss  0.31 |
    | end of validation epoch  17 | time: 63.58s | validation loss  0.99 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 17 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 18
| epoch  18 |   100/  111 batches | ms/batch 893.04 | loss  0.23 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  18 | time: 96.46s | training loss  0.29 |
    | end of validation epoch  18 | time: 63.47s | validation loss  1.09 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 18 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 19
| epoch  19 |   100/  111 batches | ms/batch 897.58 | loss  0.18 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  19 | time: 96.47s | training loss  0.28 |
    | end of validation epoch  19 | time: 63.85s | validation loss  1.15 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 19 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 20
| epoch  20 |   100/  111 batches | ms/batch 890.99 | loss  0.39 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  20 | time: 96.00s | training loss  0.28 |
    | end of validation epoch  20 | time: 63.53s | validation loss  1.27 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 20 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 21
| epoch  21 |   100/  111 batches | ms/batch 892.61 | loss  0.19 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  21 | time: 96.12s | training loss  0.26 |
    | end of validation epoch  21 | time: 63.42s | validation loss  1.19 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 21 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 22
| epoch  22 |   100/  111 batches | ms/batch 894.09 | loss  0.28 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  22 | time: 96.44s | training loss  0.24 |
    | end of validation epoch  22 | time: 63.80s | validation loss  1.09 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 22 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 23
| epoch  23 |   100/  111 batches | ms/batch 897.10 | loss  0.16 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  23 | time: 96.57s | training loss  0.24 |
    | end of validation epoch  23 | time: 63.52s | validation loss  1.01 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 23 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 24
| epoch  24 |   100/  111 batches | ms/batch 896.30 | loss  0.16 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  24 | time: 97.72s | training loss  0.21 |
    | end of validation epoch  24 | time: 63.92s | validation loss  1.11 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 24 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 25
| epoch  25 |   100/  111 batches | ms/batch 894.77 | loss  0.20 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  25 | time: 96.23s | training loss  0.21 |
    | end of validation epoch  25 | time: 63.52s | validation loss  1.16 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 25 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 26
| epoch  26 |   100/  111 batches | ms/batch 888.08 | loss  0.13 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  26 | time: 96.00s | training loss  0.20 |
    | end of validation epoch  26 | time: 63.64s | validation loss  1.14 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 26 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 27
| epoch  27 |   100/  111 batches | ms/batch 905.30 | loss  0.37 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  27 | time: 97.77s | training loss  0.21 |
    | end of validation epoch  27 | time: 63.60s | validation loss  1.22 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 27 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607]
this is epoch 28
| epoch  28 |   100/  111 batches | ms/batch 893.60 | loss  0.21 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  28 | time: 96.47s | training loss  0.20 |
    | end of validation epoch  28 | time: 63.56s | validation loss  1.11 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 28 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 29
| epoch  29 |   100/  111 batches | ms/batch 899.02 | loss  0.19 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  29 | time: 96.84s | training loss  0.19 |
    | end of validation epoch  29 | time: 63.60s | validation loss  1.13 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 29 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 30
| epoch  30 |   100/  111 batches | ms/batch 895.37 | loss  0.07 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  30 | time: 96.57s | training loss  0.18 |
    | end of validation epoch  30 | time: 63.66s | validation loss  1.27 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 30 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 31
| epoch  31 |   100/  111 batches | ms/batch 898.40 | loss  0.17 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  31 | time: 96.69s | training loss  0.18 |
    | end of validation epoch  31 | time: 63.92s | validation loss  1.09 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 31 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 32
| epoch  32 |   100/  111 batches | ms/batch 897.80 | loss  0.11 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  32 | time: 96.70s | training loss  0.16 |
    | end of validation epoch  32 | time: 63.75s | validation loss  1.21 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 32 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 33
| epoch  33 |   100/  111 batches | ms/batch 898.42 | loss  0.15 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  33 | time: 96.58s | training loss  0.17 |
    | end of validation epoch  33 | time: 63.58s | validation loss  1.06 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 33 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423]
this is epoch 34
| epoch  34 |   100/  111 batches | ms/batch 897.36 | loss  0.17 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  34 | time: 96.77s | training loss  0.15 |
    | end of validation epoch  34 | time: 63.55s | validation loss  1.16 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 34 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 35
| epoch  35 |   100/  111 batches | ms/batch 895.24 | loss  0.11 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  35 | time: 96.39s | training loss  0.15 |
    | end of validation epoch  35 | time: 63.65s | validation loss  1.22 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 35 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302]
this is epoch 36
| epoch  36 |   100/  111 batches | ms/batch 901.59 | loss  0.30 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  36 | time: 97.21s | training loss  0.15 |
    | end of validation epoch  36 | time: 63.37s | validation loss  1.41 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 36 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664]
this is epoch 37
| epoch  37 |   100/  111 batches | ms/batch 896.80 | loss  0.11 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  37 | time: 96.70s | training loss  0.15 |
    | end of validation epoch  37 | time: 63.43s | validation loss  1.42 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 37 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576]
this is epoch 38
| epoch  38 |   100/  111 batches | ms/batch 897.24 | loss  0.15 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  38 | time: 96.38s | training loss  0.13 |
    | end of validation epoch  38 | time: 63.63s | validation loss  1.21 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 38 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 39
| epoch  39 |   100/  111 batches | ms/batch 892.29 | loss  0.10 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  39 | time: 95.92s | training loss  0.14 |
    | end of validation epoch  39 | time: 63.68s | validation loss  1.21 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 39 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701]
this is epoch 40
| epoch  40 |   100/  111 batches | ms/batch 895.94 | loss  0.29 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  40 | time: 96.32s | training loss  0.15 |
    | end of validation epoch  40 | time: 63.61s | validation loss  1.26 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 40 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063]
this is epoch 41
| epoch  41 |   100/  111 batches | ms/batch 898.83 | loss  0.08 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  41 | time: 96.65s | training loss  0.11 |
    | end of validation epoch  41 | time: 63.66s | validation loss  1.20 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 41 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 42
| epoch  42 |   100/  111 batches | ms/batch 899.15 | loss  0.04 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  42 | time: 96.58s | training loss  0.12 |
    | end of validation epoch  42 | time: 63.53s | validation loss  1.26 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 42 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264]
this is epoch 43
| epoch  43 |   100/  111 batches | ms/batch 917.16 | loss  0.07 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  43 | time: 98.64s | training loss  0.14 |
    | end of validation epoch  43 | time: 64.45s | validation loss  1.29 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 43 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653]
this is epoch 44
| epoch  44 |   100/  111 batches | ms/batch 900.49 | loss  0.10 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  44 | time: 96.89s | training loss  0.11 |
    | end of validation epoch  44 | time: 63.71s | validation loss  1.34 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 44 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751]
this is epoch 45
| epoch  45 |   100/  111 batches | ms/batch 899.27 | loss  0.13 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  45 | time: 96.72s | training loss  0.12 |
    | end of validation epoch  45 | time: 63.47s | validation loss  1.32 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 45 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453]
this is epoch 46
| epoch  46 |   100/  111 batches | ms/batch 967.96 | loss  0.09 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  46 | time: 103.82s | training loss  0.12 |
    | end of validation epoch  46 | time: 63.40s | validation loss  1.28 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 46 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773]
this is epoch 47
| epoch  47 |   100/  111 batches | ms/batch 897.61 | loss  0.12 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  47 | time: 96.59s | training loss  0.11 |
    | end of validation epoch  47 | time: 63.79s | validation loss  1.41 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 47 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776]
this is epoch 48
| epoch  48 |   100/  111 batches | ms/batch 897.02 | loss  0.06 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  48 | time: 96.50s | training loss  0.11 |
    | end of validation epoch  48 | time: 63.54s | validation loss  1.22 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 48 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454]
this is epoch 49
| epoch  49 |   100/  111 batches | ms/batch 899.38 | loss  0.06 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  49 | time: 96.83s | training loss  0.09 |
    | end of validation epoch  49 | time: 63.39s | validation loss  1.22 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 49 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 50
| epoch  50 |   100/  111 batches | ms/batch 901.77 | loss  0.05 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  50 | time: 97.06s | training loss  0.10 |
    | end of validation epoch  50 | time: 63.59s | validation loss  1.35 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 50 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146]
this is epoch 51
| epoch  51 |   100/  111 batches | ms/batch 901.36 | loss  0.11 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  51 | time: 96.83s | training loss  0.10 |
    | end of validation epoch  51 | time: 63.37s | validation loss  1.18 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 51 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895]
this is epoch 52
| epoch  52 |   100/  111 batches | ms/batch 897.88 | loss  0.12 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  52 | time: 96.72s | training loss  0.10 |
    | end of validation epoch  52 | time: 63.41s | validation loss  1.18 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 52 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378]
this is epoch 53
| epoch  53 |   100/  111 batches | ms/batch 899.38 | loss  0.09 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  53 | time: 96.78s | training loss  0.10 |
    | end of validation epoch  53 | time: 63.27s | validation loss  1.38 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 53 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607]
this is epoch 54
| epoch  54 |   100/  111 batches | ms/batch 899.75 | loss  0.05 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  54 | time: 97.06s | training loss  0.10 |
    | end of validation epoch  54 | time: 63.47s | validation loss  1.43 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 54 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913]
this is epoch 55
| epoch  55 |   100/  111 batches | ms/batch 899.76 | loss  0.15 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  55 | time: 97.54s | training loss  0.09 |
    | end of validation epoch  55 | time: 63.59s | validation loss  1.29 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 55 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099]
this is epoch 56
| epoch  56 |   100/  111 batches | ms/batch 896.33 | loss  0.01 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  56 | time: 96.97s | training loss  0.10 |
    | end of validation epoch  56 | time: 63.39s | validation loss  1.81 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 56 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416]
this is epoch 57
| epoch  57 |   100/  111 batches | ms/batch 899.12 | loss  0.09 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  57 | time: 96.62s | training loss  0.09 |
    | end of validation epoch  57 | time: 63.46s | validation loss  1.38 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 57 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888]
this is epoch 58
| epoch  58 |   100/  111 batches | ms/batch 903.68 | loss  0.06 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  58 | time: 97.06s | training loss  0.08 |
    | end of validation epoch  58 | time: 63.27s | validation loss  1.63 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 58 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 59
| epoch  59 |   100/  111 batches | ms/batch 899.08 | loss  0.02 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  59 | time: 97.00s | training loss  0.09 |
    | end of validation epoch  59 | time: 63.32s | validation loss  1.34 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 59 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594]
this is epoch 60
| epoch  60 |   100/  111 batches | ms/batch 903.20 | loss  0.09 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  60 | time: 97.19s | training loss  0.08 |
    | end of validation epoch  60 | time: 63.52s | validation loss  1.38 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 60 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581]
this is epoch 61
| epoch  61 |   100/  111 batches | ms/batch 902.86 | loss  0.09 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  61 | time: 96.93s | training loss  0.09 |
    | end of validation epoch  61 | time: 63.31s | validation loss  1.24 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 61 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504]
this is epoch 62
| epoch  62 |   100/  111 batches | ms/batch 904.80 | loss  0.06 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  62 | time: 97.19s | training loss  0.09 |
    | end of validation epoch  62 | time: 63.40s | validation loss  1.43 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 62 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719]
this is epoch 63
| epoch  63 |   100/  111 batches | ms/batch 903.44 | loss  0.15 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  63 | time: 97.13s | training loss  0.08 |
    | end of validation epoch  63 | time: 63.56s | validation loss  1.20 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 63 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 64
| epoch  64 |   100/  111 batches | ms/batch 899.81 | loss  0.04 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  64 | time: 96.97s | training loss  0.08 |
    | end of validation epoch  64 | time: 63.32s | validation loss  1.42 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 64 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562]
this is epoch 65
| epoch  65 |   100/  111 batches | ms/batch 902.28 | loss  0.07 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  65 | time: 97.04s | training loss  0.07 |
    | end of validation epoch  65 | time: 63.87s | validation loss  1.37 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 65 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 66
| epoch  66 |   100/  111 batches | ms/batch 902.02 | loss  0.06 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  66 | time: 96.99s | training loss  0.08 |
    | end of validation epoch  66 | time: 63.22s | validation loss  1.30 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 66 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717]
this is epoch 67
| epoch  67 |   100/  111 batches | ms/batch 901.77 | loss  0.02 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  67 | time: 97.27s | training loss  0.07 |
    | end of validation epoch  67 | time: 63.40s | validation loss  1.33 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 67 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 68
| epoch  68 |   100/  111 batches | ms/batch 904.98 | loss  0.11 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  68 | time: 97.44s | training loss  0.08 |
    | end of validation epoch  68 | time: 63.33s | validation loss  1.47 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 68 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672]
this is epoch 69
| epoch  69 |   100/  111 batches | ms/batch 901.43 | loss  0.06 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  69 | time: 96.90s | training loss  0.08 |
    | end of validation epoch  69 | time: 63.29s | validation loss  1.33 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 69 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881]
this is epoch 70
| epoch  70 |   100/  111 batches | ms/batch 903.50 | loss  0.02 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  70 | time: 97.22s | training loss  0.08 |
    | end of validation epoch  70 | time: 63.26s | validation loss  1.42 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 70 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107]
this is epoch 71
| epoch  71 |   100/  111 batches | ms/batch 902.89 | loss  0.06 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  71 | time: 97.54s | training loss  0.07 |
    | end of validation epoch  71 | time: 63.23s | validation loss  1.39 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 71 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 72
| epoch  72 |   100/  111 batches | ms/batch 897.81 | loss  0.06 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  72 | time: 96.79s | training loss  0.07 |
    | end of validation epoch  72 | time: 63.32s | validation loss  1.60 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 72 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295]
this is epoch 73
| epoch  73 |   100/  111 batches | ms/batch 903.53 | loss  0.05 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  73 | time: 97.21s | training loss  0.07 |
    | end of validation epoch  73 | time: 63.29s | validation loss  1.45 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 73 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 74
| epoch  74 |   100/  111 batches | ms/batch 899.22 | loss  0.04 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  74 | time: 96.84s | training loss  0.07 |
    | end of validation epoch  74 | time: 63.14s | validation loss  1.40 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 74 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 75
| epoch  75 |   100/  111 batches | ms/batch 901.08 | loss  0.29 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  75 | time: 96.94s | training loss  0.07 |
    | end of validation epoch  75 | time: 63.55s | validation loss  1.49 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 75 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 76
| epoch  76 |   100/  111 batches | ms/batch 900.02 | loss  0.02 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  76 | time: 96.77s | training loss  0.05 |
    | end of validation epoch  76 | time: 63.12s | validation loss  1.45 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 76 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 77
| epoch  77 |   100/  111 batches | ms/batch 907.78 | loss  0.12 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  77 | time: 97.49s | training loss  0.07 |
    | end of validation epoch  77 | time: 63.61s | validation loss  1.34 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 77 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318]
this is epoch 78
| epoch  78 |   100/  111 batches | ms/batch 903.05 | loss  0.06 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  78 | time: 97.19s | training loss  0.06 |
    | end of validation epoch  78 | time: 63.53s | validation loss  1.33 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 78 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106]
this is epoch 79
| epoch  79 |   100/  111 batches | ms/batch 899.27 | loss  0.06 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  79 | time: 96.83s | training loss  0.07 |
    | end of validation epoch  79 | time: 63.53s | validation loss  1.57 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 79 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482]
this is epoch 80
| epoch  80 |   100/  111 batches | ms/batch 897.69 | loss  0.13 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  80 | time: 96.77s | training loss  0.07 |
    | end of validation epoch  80 | time: 63.63s | validation loss  1.42 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 80 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895, 0.06539155118301646] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482, 1.4190282911101046]
this is epoch 81
| epoch  81 |   100/  111 batches | ms/batch 899.76 | loss  0.13 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  81 | time: 96.67s | training loss  0.06 |
    | end of validation epoch  81 | time: 63.43s | validation loss  1.57 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 81 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895, 0.06539155118301646, 0.05786744407839603] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482, 1.4190282911101046, 1.5690147103850904]
this is epoch 82
| epoch  82 |   100/  111 batches | ms/batch 897.99 | loss  0.17 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  82 | time: 96.53s | training loss  0.06 |
    | end of validation epoch  82 | time: 63.64s | validation loss  1.49 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 82 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895, 0.06539155118301646, 0.05786744407839603, 0.058374651103607705] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482, 1.4190282911101046, 1.5690147103850904, 1.4905737634156442]
this is epoch 83
| epoch  83 |   100/  111 batches | ms/batch 902.84 | loss  0.11 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  83 | time: 97.48s | training loss  0.05 |
    | end of validation epoch  83 | time: 63.62s | validation loss  1.58 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 83 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895, 0.06539155118301646, 0.05786744407839603, 0.058374651103607705, 0.05302269139058619] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482, 1.4190282911101046, 1.5690147103850904, 1.4905737634156442, 1.5797784555858623]
this is epoch 84
| epoch  84 |   100/  111 batches | ms/batch 897.62 | loss  0.05 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  84 | time: 98.62s | training loss  0.06 |
    | end of validation epoch  84 | time: 63.34s | validation loss  1.40 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 84 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895, 0.06539155118301646, 0.05786744407839603, 0.058374651103607705, 0.05302269139058619, 0.06128728354500758] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482, 1.4190282911101046, 1.5690147103850904, 1.4905737634156442, 1.5797784555858623, 1.395918592674813]
this is epoch 85
| epoch  85 |   100/  111 batches | ms/batch 899.33 | loss  0.03 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  85 | time: 97.40s | training loss  0.06 |
    | end of validation epoch  85 | time: 63.41s | validation loss  1.69 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 85 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895, 0.06539155118301646, 0.05786744407839603, 0.058374651103607705, 0.05302269139058619, 0.06128728354500758, 0.06184413673372956] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482, 1.4190282911101046, 1.5690147103850904, 1.4905737634156442, 1.5797784555858623, 1.395918592674813, 1.6891719924363617]
this is epoch 86
| epoch  86 |   100/  111 batches | ms/batch 904.34 | loss  0.03 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  86 | time: 97.23s | training loss  0.06 |
    | end of validation epoch  86 | time: 63.58s | validation loss  1.68 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 86 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895, 0.06539155118301646, 0.05786744407839603, 0.058374651103607705, 0.05302269139058619, 0.06128728354500758, 0.06184413673372956, 0.05703652922382897] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482, 1.4190282911101046, 1.5690147103850904, 1.4905737634156442, 1.5797784555858623, 1.395918592674813, 1.6891719924363617, 1.6782279529288644]
this is epoch 87
| epoch  87 |   100/  111 batches | ms/batch 928.51 | loss  0.02 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  87 | time: 99.78s | training loss  0.05 |
    | end of validation epoch  87 | time: 64.17s | validation loss  1.56 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 87 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895, 0.06539155118301646, 0.05786744407839603, 0.058374651103607705, 0.05302269139058619, 0.06128728354500758, 0.06184413673372956, 0.05703652922382897, 0.051124330257644526] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482, 1.4190282911101046, 1.5690147103850904, 1.4905737634156442, 1.5797784555858623, 1.395918592674813, 1.6891719924363617, 1.6782279529288644, 1.5614791343493077]
this is epoch 88
| epoch  88 |   100/  111 batches | ms/batch 901.46 | loss  0.17 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  88 | time: 97.54s | training loss  0.05 |
    | end of validation epoch  88 | time: 63.55s | validation loss  1.59 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 88 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895, 0.06539155118301646, 0.05786744407839603, 0.058374651103607705, 0.05302269139058619, 0.06128728354500758, 0.06184413673372956, 0.05703652922382897, 0.051124330257644526, 0.05097425841046749] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482, 1.4190282911101046, 1.5690147103850904, 1.4905737634156442, 1.5797784555858623, 1.395918592674813, 1.6891719924363617, 1.6782279529288644, 1.5614791343493077, 1.5860836202045903]
this is epoch 89
| epoch  89 |   100/  111 batches | ms/batch 900.08 | loss  0.06 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  89 | time: 96.74s | training loss  0.06 |
    | end of validation epoch  89 | time: 63.71s | validation loss  1.61 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 89 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895, 0.06539155118301646, 0.05786744407839603, 0.058374651103607705, 0.05302269139058619, 0.06128728354500758, 0.06184413673372956, 0.05703652922382897, 0.051124330257644526, 0.05097425841046749, 0.06153136836616574] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482, 1.4190282911101046, 1.5690147103850904, 1.4905737634156442, 1.5797784555858623, 1.395918592674813, 1.6891719924363617, 1.6782279529288644, 1.5614791343493077, 1.5860836202045903, 1.6092194196486769]
this is epoch 90
| epoch  90 |   100/  111 batches | ms/batch 899.16 | loss  0.02 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  90 | time: 96.91s | training loss  0.06 |
    | end of validation epoch  90 | time: 63.80s | validation loss  1.65 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 90 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895, 0.06539155118301646, 0.05786744407839603, 0.058374651103607705, 0.05302269139058619, 0.06128728354500758, 0.06184413673372956, 0.05703652922382897, 0.051124330257644526, 0.05097425841046749, 0.06153136836616574, 0.06073831844873525] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482, 1.4190282911101046, 1.5690147103850904, 1.4905737634156442, 1.5797784555858623, 1.395918592674813, 1.6891719924363617, 1.6782279529288644, 1.5614791343493077, 1.5860836202045903, 1.6092194196486769, 1.6505018545431085]
this is epoch 91
| epoch  91 |   100/  111 batches | ms/batch 896.58 | loss  0.13 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  91 | time: 96.41s | training loss  0.07 |
    | end of validation epoch  91 | time: 63.50s | validation loss  1.91 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 91 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895, 0.06539155118301646, 0.05786744407839603, 0.058374651103607705, 0.05302269139058619, 0.06128728354500758, 0.06184413673372956, 0.05703652922382897, 0.051124330257644526, 0.05097425841046749, 0.06153136836616574, 0.06073831844873525, 0.06989921852191155] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482, 1.4190282911101046, 1.5690147103850904, 1.4905737634156442, 1.5797784555858623, 1.395918592674813, 1.6891719924363617, 1.6782279529288644, 1.5614791343493077, 1.5860836202045903, 1.6092194196486769, 1.6505018545431085, 1.910642501451851]
this is epoch 92
| epoch  92 |   100/  111 batches | ms/batch 898.51 | loss  0.01 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  92 | time: 96.74s | training loss  0.05 |
    | end of validation epoch  92 | time: 63.52s | validation loss  1.42 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 92 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895, 0.06539155118301646, 0.05786744407839603, 0.058374651103607705, 0.05302269139058619, 0.06128728354500758, 0.06184413673372956, 0.05703652922382897, 0.051124330257644526, 0.05097425841046749, 0.06153136836616574, 0.06073831844873525, 0.06989921852191155, 0.04867289771183251] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482, 1.4190282911101046, 1.5690147103850904, 1.4905737634156442, 1.5797784555858623, 1.395918592674813, 1.6891719924363617, 1.6782279529288644, 1.5614791343493077, 1.5860836202045903, 1.6092194196486769, 1.6505018545431085, 1.910642501451851, 1.422885483674084]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 93
| epoch  93 |   100/  111 batches | ms/batch 899.19 | loss  0.02 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  93 | time: 96.74s | training loss  0.05 |
    | end of validation epoch  93 | time: 63.55s | validation loss  1.43 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 93 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895, 0.06539155118301646, 0.05786744407839603, 0.058374651103607705, 0.05302269139058619, 0.06128728354500758, 0.06184413673372956, 0.05703652922382897, 0.051124330257644526, 0.05097425841046749, 0.06153136836616574, 0.06073831844873525, 0.06989921852191155, 0.04867289771183251, 0.051010601809835646] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482, 1.4190282911101046, 1.5690147103850904, 1.4905737634156442, 1.5797784555858623, 1.395918592674813, 1.6891719924363617, 1.6782279529288644, 1.5614791343493077, 1.5860836202045903, 1.6092194196486769, 1.6505018545431085, 1.910642501451851, 1.422885483674084, 1.4344468187579575]
this is epoch 94
| epoch  94 |   100/  111 batches | ms/batch 898.71 | loss  0.02 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  94 | time: 96.78s | training loss  0.05 |
    | end of validation epoch  94 | time: 63.89s | validation loss  1.53 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 94 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895, 0.06539155118301646, 0.05786744407839603, 0.058374651103607705, 0.05302269139058619, 0.06128728354500758, 0.06184413673372956, 0.05703652922382897, 0.051124330257644526, 0.05097425841046749, 0.06153136836616574, 0.06073831844873525, 0.06989921852191155, 0.04867289771183251, 0.051010601809835646, 0.05055916144906938] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482, 1.4190282911101046, 1.5690147103850904, 1.4905737634156442, 1.5797784555858623, 1.395918592674813, 1.6891719924363617, 1.6782279529288644, 1.5614791343493077, 1.5860836202045903, 1.6092194196486769, 1.6505018545431085, 1.910642501451851, 1.422885483674084, 1.4344468187579575, 1.5277941057065618]
this is epoch 95
| epoch  95 |   100/  111 batches | ms/batch 897.68 | loss  0.03 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  95 | time: 96.55s | training loss  0.04 |
    | end of validation epoch  95 | time: 63.55s | validation loss  1.57 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 95 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895, 0.06539155118301646, 0.05786744407839603, 0.058374651103607705, 0.05302269139058619, 0.06128728354500758, 0.06184413673372956, 0.05703652922382897, 0.051124330257644526, 0.05097425841046749, 0.06153136836616574, 0.06073831844873525, 0.06989921852191155, 0.04867289771183251, 0.051010601809835646, 0.05055916144906938, 0.041173182331394775] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482, 1.4190282911101046, 1.5690147103850904, 1.4905737634156442, 1.5797784555858623, 1.395918592674813, 1.6891719924363617, 1.6782279529288644, 1.5614791343493077, 1.5860836202045903, 1.6092194196486769, 1.6505018545431085, 1.910642501451851, 1.422885483674084, 1.4344468187579575, 1.5277941057065618, 1.5725407352632221]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 96
| epoch  96 |   100/  111 batches | ms/batch 896.95 | loss  0.06 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  96 | time: 97.08s | training loss  0.06 |
    | end of validation epoch  96 | time: 63.66s | validation loss  1.61 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 96 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895, 0.06539155118301646, 0.05786744407839603, 0.058374651103607705, 0.05302269139058619, 0.06128728354500758, 0.06184413673372956, 0.05703652922382897, 0.051124330257644526, 0.05097425841046749, 0.06153136836616574, 0.06073831844873525, 0.06989921852191155, 0.04867289771183251, 0.051010601809835646, 0.05055916144906938, 0.041173182331394775, 0.05634829992646569] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482, 1.4190282911101046, 1.5690147103850904, 1.4905737634156442, 1.5797784555858623, 1.395918592674813, 1.6891719924363617, 1.6782279529288644, 1.5614791343493077, 1.5860836202045903, 1.6092194196486769, 1.6505018545431085, 1.910642501451851, 1.422885483674084, 1.4344468187579575, 1.5277941057065618, 1.5725407352632221, 1.6059406791537185]
this is epoch 97
| epoch  97 |   100/  111 batches | ms/batch 894.34 | loss  0.02 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  97 | time: 96.19s | training loss  0.04 |
    | end of validation epoch  97 | time: 63.63s | validation loss  1.51 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 97 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895, 0.06539155118301646, 0.05786744407839603, 0.058374651103607705, 0.05302269139058619, 0.06128728354500758, 0.06184413673372956, 0.05703652922382897, 0.051124330257644526, 0.05097425841046749, 0.06153136836616574, 0.06073831844873525, 0.06989921852191155, 0.04867289771183251, 0.051010601809835646, 0.05055916144906938, 0.041173182331394775, 0.05634829992646569, 0.04259964739819905] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482, 1.4190282911101046, 1.5690147103850904, 1.4905737634156442, 1.5797784555858623, 1.395918592674813, 1.6891719924363617, 1.6782279529288644, 1.5614791343493077, 1.5860836202045903, 1.6092194196486769, 1.6505018545431085, 1.910642501451851, 1.422885483674084, 1.4344468187579575, 1.5277941057065618, 1.5725407352632221, 1.6059406791537185, 1.5141391720972024]
this is epoch 98
| epoch  98 |   100/  111 batches | ms/batch 896.71 | loss  0.12 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  98 | time: 96.41s | training loss  0.04 |
    | end of validation epoch  98 | time: 63.51s | validation loss  1.54 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 98 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895, 0.06539155118301646, 0.05786744407839603, 0.058374651103607705, 0.05302269139058619, 0.06128728354500758, 0.06184413673372956, 0.05703652922382897, 0.051124330257644526, 0.05097425841046749, 0.06153136836616574, 0.06073831844873525, 0.06989921852191155, 0.04867289771183251, 0.051010601809835646, 0.05055916144906938, 0.041173182331394775, 0.05634829992646569, 0.04259964739819905, 0.04379151756497654] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482, 1.4190282911101046, 1.5690147103850904, 1.4905737634156442, 1.5797784555858623, 1.395918592674813, 1.6891719924363617, 1.6782279529288644, 1.5614791343493077, 1.5860836202045903, 1.6092194196486769, 1.6505018545431085, 1.910642501451851, 1.422885483674084, 1.4344468187579575, 1.5277941057065618, 1.5725407352632221, 1.6059406791537185, 1.5141391720972024, 1.5430196241359226]
this is epoch 99
| epoch  99 |   100/  111 batches | ms/batch 892.59 | loss  0.01 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  99 | time: 96.60s | training loss  0.04 |
    | end of validation epoch  99 | time: 63.67s | validation loss  1.51 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 99 training loss is  [1.6638764282604595, 1.1267886532319558, 0.9685718970255809, 0.8247144657212335, 0.7650195123913052, 0.6684534015419247, 0.6182742610171035, 0.5594242958872168, 0.5047571618814726, 0.46478512346207557, 0.4322208179546906, 0.413803252416688, 0.3690247244394577, 0.35371895738550135, 0.3484432968470427, 0.3176743582830773, 0.30844432981433095, 0.28737729499200443, 0.28317139391695056, 0.2811506719471098, 0.26035585408812173, 0.23821511435079146, 0.23504501339551565, 0.2094209447905824, 0.20868967298988825, 0.2020693522047352, 0.20620172947376697, 0.19770949199661478, 0.1889502238314431, 0.17939424195939357, 0.17912340842120283, 0.16311475164718456, 0.17136757481876794, 0.14584339611433647, 0.14739846767068984, 0.15470674956167066, 0.15335249746436472, 0.1317098554861438, 0.13882313923792797, 0.14622728885696815, 0.10805665968439064, 0.11680994464738949, 0.13768405698843905, 0.11484380116736567, 0.12191373418580305, 0.11957437370543007, 0.113692460145365, 0.11202094989182713, 0.0929362040415809, 0.10196385113102896, 0.09904054834230526, 0.10383338113692966, 0.1039223236677883, 0.09970736209940803, 0.09494819562580134, 0.10003622140534021, 0.0933458760783479, 0.08049981479809896, 0.08618181159400994, 0.08138062054845127, 0.09352504915918584, 0.09054673389271573, 0.07822811794844833, 0.08467836214883907, 0.07395567635896506, 0.0800387633813394, 0.07249455739584593, 0.07732104825543927, 0.07613780260555916, 0.07685035272493018, 0.07175161187780334, 0.07315385960008916, 0.07170436072356261, 0.07122526556958218, 0.06627356090691981, 0.050742585211992264, 0.07348670312077613, 0.057610418945383116, 0.07399877684341895, 0.06539155118301646, 0.05786744407839603, 0.058374651103607705, 0.05302269139058619, 0.06128728354500758, 0.06184413673372956, 0.05703652922382897, 0.051124330257644526, 0.05097425841046749, 0.06153136836616574, 0.06073831844873525, 0.06989921852191155, 0.04867289771183251, 0.051010601809835646, 0.05055916144906938, 0.041173182331394775, 0.05634829992646569, 0.04259964739819905, 0.04379151756497654, 0.04291627224039723] validation loss is  [1.0953512836325292, 1.019932325812988, 0.93323451820955, 0.9892737559663752, 1.0718601124438767, 0.9752183564317723, 0.9829988100876411, 1.0417603719979525, 1.0509730903237748, 1.0460081728718553, 1.1898189301330906, 0.9959685517242178, 0.9572148521741232, 1.1212385251031567, 1.1048513424999935, 1.1602239995263517, 0.9881346285692416, 1.0874990415371333, 1.1511911168539275, 1.273225062546165, 1.1883564451127313, 1.0914261363407907, 1.0063391907800299, 1.1108460871425148, 1.1569221442429505, 1.1422816467044565, 1.2192772283257607, 1.1107776726130396, 1.1251896325848065, 1.2666801326946977, 1.0910002609404426, 1.2140527343920742, 1.0580841513486423, 1.1610789708017062, 1.223563955592302, 1.4094209149843664, 1.4206299096161576, 1.2081148417006868, 1.2135442036669701, 1.2629310516786063, 1.1991447507947062, 1.2622209593537264, 1.2879565910746653, 1.3422627465042751, 1.3191444498758453, 1.28492389410773, 1.4096822681203776, 1.2248883060965454, 1.2227259117480571, 1.3533191027042146, 1.1816231829385895, 1.1828210339105378, 1.3758351542055607, 1.4310348421937913, 1.288556346335099, 1.8135184768325416, 1.3845169080110888, 1.6294928087930505, 1.3399799963614594, 1.3770791619123581, 1.238412231284504, 1.4327693935677719, 1.1962940947657141, 1.4163547760690562, 1.3742181140193377, 1.2951891490568717, 1.330049413741411, 1.472554401945672, 1.32807051496881, 1.4247824197276107, 1.3937363707761203, 1.6018666683206295, 1.4457477807203152, 1.4016325070988387, 1.4948416226895158, 1.4544004898295195, 1.3366721779651318, 1.3260461064395106, 1.5686961392378482, 1.4190282911101046, 1.5690147103850904, 1.4905737634156442, 1.5797784555858623, 1.395918592674813, 1.6891719924363617, 1.6782279529288644, 1.5614791343493077, 1.5860836202045903, 1.6092194196486769, 1.6505018545431085, 1.910642501451851, 1.422885483674084, 1.4344468187579575, 1.5277941057065618, 1.5725407352632221, 1.6059406791537185, 1.5141391720972024, 1.5430196241359226, 1.510642774560741]

/run/nvme/job_2961505/data
{'debug': False, 'num_workers': 4, 'seed': 0, 'n_epochs': 100, 'batch_size': 64, 'vgg_path': '/vgg-sound/', 'filepath': '../selected_files.csv', 'unwanted_files_path': '../../unwanted.csv', 'audio_fps': 16000, 'audio_dur': 1, 'spectrogram_fps': 100.0, 'n_fft': 512, 'n_mels': 64, 'model_type': 'audio', 'num_classes': 309, 'feat_name': 'pool', 'pooling_op': None, 'feat_dim': 512, 'use_dropout': True, 'dropout': 0.5}
use_cude True
all the training files is 38007
training has  30406
all the training files is 38007
validation has  7601
Directory  ./audio_model/  Created 
use_cude True
-----------start training
this is epoch 1
| epoch   1 |   100/  475 batches | ms/batch 1030.86 | loss  5.99 |
| epoch   1 |   200/  475 batches | ms/batch 712.96 | loss  5.91 |
| epoch   1 |   300/  475 batches | ms/batch 574.84 | loss  5.95 |
| epoch   1 |   400/  475 batches | ms/batch 525.44 | loss  5.69 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   1 | time: 243.55s | training loss  5.91 |
    | end of validation epoch   1 | time: 123.04s | validation loss  5.62 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 1 training loss is  [5.9065556415758635] validation loss is  [5.62185000571884]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 2
| epoch   2 |   100/  475 batches | ms/batch 405.06 | loss  5.62 |
| epoch   2 |   200/  475 batches | ms/batch 408.45 | loss  5.59 |
| epoch   2 |   300/  475 batches | ms/batch 372.10 | loss  5.55 |
| epoch   2 |   400/  475 batches | ms/batch 356.16 | loss  5.52 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   2 | time: 165.89s | training loss  5.61 |
    | end of validation epoch   2 | time: 122.07s | validation loss  5.35 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 2 training loss is  [5.9065556415758635, 5.608660655774568] validation loss is  [5.62185000571884, 5.345151797062209]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 3
| epoch   3 |   100/  475 batches | ms/batch 443.76 | loss  5.45 |
| epoch   3 |   200/  475 batches | ms/batch 362.76 | loss  5.27 |
| epoch   3 |   300/  475 batches | ms/batch 337.99 | loss  5.35 |
| epoch   3 |   400/  475 batches | ms/batch 323.67 | loss  5.19 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   3 | time: 153.69s | training loss  5.36 |
    | end of validation epoch   3 | time: 121.31s | validation loss  4.99 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 3 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 4
| epoch   4 |   100/  475 batches | ms/batch 453.32 | loss  5.28 |
| epoch   4 |   200/  475 batches | ms/batch 391.89 | loss  5.22 |
| epoch   4 |   300/  475 batches | ms/batch 352.68 | loss  4.89 |
| epoch   4 |   400/  475 batches | ms/batch 341.12 | loss  4.99 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   4 | time: 156.56s | training loss  5.16 |
    | end of validation epoch   4 | time: 135.47s | validation loss  4.73 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 4 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 5
| epoch   5 |   100/  475 batches | ms/batch 487.34 | loss  4.82 |
| epoch   5 |   200/  475 batches | ms/batch 394.32 | loss  5.01 |
| epoch   5 |   300/  475 batches | ms/batch 375.52 | loss  4.91 |
| epoch   5 |   400/  475 batches | ms/batch 380.07 | loss  4.91 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   5 | time: 173.31s | training loss  4.97 |
    | end of validation epoch   5 | time: 113.52s | validation loss  4.53 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 5 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 6
| epoch   6 |   100/  475 batches | ms/batch 321.80 | loss  4.91 |
| epoch   6 |   200/  475 batches | ms/batch 300.60 | loss  4.73 |
| epoch   6 |   300/  475 batches | ms/batch 319.09 | loss  5.01 |
| epoch   6 |   400/  475 batches | ms/batch 308.89 | loss  4.76 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   6 | time: 144.57s | training loss  4.82 |
    | end of validation epoch   6 | time: 117.28s | validation loss  4.28 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 6 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 7
| epoch   7 |   100/  475 batches | ms/batch 340.93 | loss  5.08 |
| epoch   7 |   200/  475 batches | ms/batch 306.05 | loss  4.72 |
| epoch   7 |   300/  475 batches | ms/batch 296.52 | loss  4.86 |
| epoch   7 |   400/  475 batches | ms/batch 293.21 | loss  4.72 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   7 | time: 142.06s | training loss  4.70 |
    | end of validation epoch   7 | time: 120.49s | validation loss  4.14 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 7 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 8
| epoch   8 |   100/  475 batches | ms/batch 372.26 | loss  4.52 |
| epoch   8 |   200/  475 batches | ms/batch 358.91 | loss  4.57 |
| epoch   8 |   300/  475 batches | ms/batch 330.14 | loss  4.44 |
| epoch   8 |   400/  475 batches | ms/batch 319.83 | loss  4.59 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   8 | time: 148.21s | training loss  4.59 |
    | end of validation epoch   8 | time: 120.40s | validation loss  4.06 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 8 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 9
| epoch   9 |   100/  475 batches | ms/batch 365.48 | loss  4.45 |
| epoch   9 |   200/  475 batches | ms/batch 332.55 | loss  4.79 |
| epoch   9 |   300/  475 batches | ms/batch 326.60 | loss  4.32 |
| epoch   9 |   400/  475 batches | ms/batch 327.21 | loss  4.65 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   9 | time: 151.81s | training loss  4.49 |
    | end of validation epoch   9 | time: 118.32s | validation loss  3.93 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 9 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 10
| epoch  10 |   100/  475 batches | ms/batch 476.32 | loss  4.27 |
| epoch  10 |   200/  475 batches | ms/batch 417.67 | loss  4.16 |
| epoch  10 |   300/  475 batches | ms/batch 372.96 | loss  4.29 |
| epoch  10 |   400/  475 batches | ms/batch 370.25 | loss  4.52 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  10 | time: 171.37s | training loss  4.41 |
    | end of validation epoch  10 | time: 122.11s | validation loss  3.82 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 10 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 11
| epoch  11 |   100/  475 batches | ms/batch 360.13 | loss  4.74 |
| epoch  11 |   200/  475 batches | ms/batch 320.61 | loss  4.58 |
| epoch  11 |   300/  475 batches | ms/batch 324.23 | loss  3.98 |
| epoch  11 |   400/  475 batches | ms/batch 314.32 | loss  4.40 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  11 | time: 146.03s | training loss  4.36 |
    | end of validation epoch  11 | time: 117.89s | validation loss  3.92 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 11 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 12
| epoch  12 |   100/  475 batches | ms/batch 343.25 | loss  4.65 |
| epoch  12 |   200/  475 batches | ms/batch 311.07 | loss  4.66 |
| epoch  12 |   300/  475 batches | ms/batch 305.48 | loss  4.32 |
| epoch  12 |   400/  475 batches | ms/batch 298.53 | loss  3.94 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  12 | time: 140.02s | training loss  4.28 |
    | end of validation epoch  12 | time: 115.14s | validation loss  3.69 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 12 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 13
| epoch  13 |   100/  475 batches | ms/batch 303.99 | loss  4.22 |
| epoch  13 |   200/  475 batches | ms/batch 288.71 | loss  4.26 |
| epoch  13 |   300/  475 batches | ms/batch 283.65 | loss  4.13 |
| epoch  13 |   400/  475 batches | ms/batch 280.68 | loss  4.21 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  13 | time: 134.30s | training loss  4.21 |
    | end of validation epoch  13 | time: 114.16s | validation loss  3.61 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 13 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 14
| epoch  14 |   100/  475 batches | ms/batch 330.41 | loss  4.00 |
| epoch  14 |   200/  475 batches | ms/batch 306.83 | loss  4.32 |
| epoch  14 |   300/  475 batches | ms/batch 304.51 | loss  4.88 |
| epoch  14 |   400/  475 batches | ms/batch 302.51 | loss  4.22 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  14 | time: 142.15s | training loss  4.16 |
    | end of validation epoch  14 | time: 117.91s | validation loss  3.56 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 14 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 15
| epoch  15 |   100/  475 batches | ms/batch 352.99 | loss  4.17 |
| epoch  15 |   200/  475 batches | ms/batch 335.69 | loss  3.78 |
| epoch  15 |   300/  475 batches | ms/batch 318.00 | loss  3.79 |
| epoch  15 |   400/  475 batches | ms/batch 308.24 | loss  4.28 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  15 | time: 147.72s | training loss  4.10 |
    | end of validation epoch  15 | time: 123.33s | validation loss  3.50 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 15 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 16
| epoch  16 |   100/  475 batches | ms/batch 429.49 | loss  3.99 |
| epoch  16 |   200/  475 batches | ms/batch 355.71 | loss  4.12 |
| epoch  16 |   300/  475 batches | ms/batch 332.71 | loss  3.70 |
| epoch  16 |   400/  475 batches | ms/batch 327.16 | loss  3.94 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  16 | time: 152.08s | training loss  4.05 |
    | end of validation epoch  16 | time: 118.45s | validation loss  3.42 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 16 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 17
| epoch  17 |   100/  475 batches | ms/batch 382.79 | loss  3.87 |
| epoch  17 |   200/  475 batches | ms/batch 334.83 | loss  4.02 |
| epoch  17 |   300/  475 batches | ms/batch 316.75 | loss  4.06 |
| epoch  17 |   400/  475 batches | ms/batch 308.89 | loss  4.12 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  17 | time: 144.41s | training loss  4.01 |
    | end of validation epoch  17 | time: 116.73s | validation loss  3.38 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 17 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 18
| epoch  18 |   100/  475 batches | ms/batch 323.78 | loss  3.78 |
| epoch  18 |   200/  475 batches | ms/batch 307.63 | loss  3.94 |
| epoch  18 |   300/  475 batches | ms/batch 296.61 | loss  3.91 |
| epoch  18 |   400/  475 batches | ms/batch 294.07 | loss  3.98 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  18 | time: 140.26s | training loss  3.97 |
    | end of validation epoch  18 | time: 115.79s | validation loss  3.37 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 18 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 19
| epoch  19 |   100/  475 batches | ms/batch 329.17 | loss  3.99 |
| epoch  19 |   200/  475 batches | ms/batch 306.50 | loss  3.60 |
| epoch  19 |   300/  475 batches | ms/batch 300.75 | loss  4.01 |
| epoch  19 |   400/  475 batches | ms/batch 299.32 | loss  3.66 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  19 | time: 141.98s | training loss  3.94 |
    | end of validation epoch  19 | time: 119.23s | validation loss  3.37 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 19 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 20
| epoch  20 |   100/  475 batches | ms/batch 345.38 | loss  4.03 |
| epoch  20 |   200/  475 batches | ms/batch 311.76 | loss  3.93 |
| epoch  20 |   300/  475 batches | ms/batch 309.32 | loss  3.93 |
| epoch  20 |   400/  475 batches | ms/batch 299.42 | loss  3.68 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  20 | time: 142.25s | training loss  3.90 |
    | end of validation epoch  20 | time: 123.29s | validation loss  3.30 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 20 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 21
| epoch  21 |   100/  475 batches | ms/batch 354.61 | loss  3.63 |
| epoch  21 |   200/  475 batches | ms/batch 317.61 | loss  4.37 |
| epoch  21 |   300/  475 batches | ms/batch 313.97 | loss  3.72 |
| epoch  21 |   400/  475 batches | ms/batch 310.64 | loss  3.70 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  21 | time: 146.91s | training loss  3.86 |
    | end of validation epoch  21 | time: 118.34s | validation loss  3.25 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 21 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 22
| epoch  22 |   100/  475 batches | ms/batch 326.75 | loss  3.61 |
| epoch  22 |   200/  475 batches | ms/batch 306.01 | loss  3.79 |
| epoch  22 |   300/  475 batches | ms/batch 300.88 | loss  3.99 |
| epoch  22 |   400/  475 batches | ms/batch 295.56 | loss  4.03 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  22 | time: 138.84s | training loss  3.84 |
    | end of validation epoch  22 | time: 116.64s | validation loss  3.23 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 22 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 23
| epoch  23 |   100/  475 batches | ms/batch 311.67 | loss  3.93 |
| epoch  23 |   200/  475 batches | ms/batch 293.56 | loss  3.83 |
| epoch  23 |   300/  475 batches | ms/batch 292.67 | loss  3.75 |
| epoch  23 |   400/  475 batches | ms/batch 291.89 | loss  3.97 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  23 | time: 137.59s | training loss  3.81 |
    | end of validation epoch  23 | time: 120.75s | validation loss  3.21 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 23 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 24
| epoch  24 |   100/  475 batches | ms/batch 361.59 | loss  3.22 |
| epoch  24 |   200/  475 batches | ms/batch 326.27 | loss  3.81 |
| epoch  24 |   300/  475 batches | ms/batch 319.68 | loss  3.74 |
| epoch  24 |   400/  475 batches | ms/batch 313.95 | loss  3.42 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  24 | time: 147.47s | training loss  3.77 |
    | end of validation epoch  24 | time: 121.63s | validation loss  3.14 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 24 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 25
| epoch  25 |   100/  475 batches | ms/batch 385.93 | loss  3.92 |
| epoch  25 |   200/  475 batches | ms/batch 332.32 | loss  3.64 |
| epoch  25 |   300/  475 batches | ms/batch 315.79 | loss  3.40 |
| epoch  25 |   400/  475 batches | ms/batch 311.49 | loss  3.45 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  25 | time: 146.28s | training loss  3.75 |
    | end of validation epoch  25 | time: 118.84s | validation loss  3.11 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 25 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 26
| epoch  26 |   100/  475 batches | ms/batch 397.48 | loss  3.58 |
| epoch  26 |   200/  475 batches | ms/batch 345.88 | loss  3.64 |
| epoch  26 |   300/  475 batches | ms/batch 324.03 | loss  3.72 |
| epoch  26 |   400/  475 batches | ms/batch 317.08 | loss  3.90 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  26 | time: 148.41s | training loss  3.72 |
    | end of validation epoch  26 | time: 118.67s | validation loss  3.12 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 26 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 27
| epoch  27 |   100/  475 batches | ms/batch 349.28 | loss  3.52 |
| epoch  27 |   200/  475 batches | ms/batch 313.87 | loss  3.67 |
| epoch  27 |   300/  475 batches | ms/batch 308.14 | loss  3.57 |
| epoch  27 |   400/  475 batches | ms/batch 301.16 | loss  3.79 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  27 | time: 142.30s | training loss  3.71 |
    | end of validation epoch  27 | time: 115.47s | validation loss  3.04 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 27 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 28
| epoch  28 |   100/  475 batches | ms/batch 303.94 | loss  4.10 |
| epoch  28 |   200/  475 batches | ms/batch 290.14 | loss  4.04 |
| epoch  28 |   300/  475 batches | ms/batch 284.22 | loss  3.60 |
| epoch  28 |   400/  475 batches | ms/batch 289.92 | loss  3.41 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  28 | time: 136.88s | training loss  3.69 |
    | end of validation epoch  28 | time: 116.61s | validation loss  3.05 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 28 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 29
| epoch  29 |   100/  475 batches | ms/batch 337.33 | loss  3.83 |
| epoch  29 |   200/  475 batches | ms/batch 320.55 | loss  3.55 |
| epoch  29 |   300/  475 batches | ms/batch 311.99 | loss  3.35 |
| epoch  29 |   400/  475 batches | ms/batch 305.18 | loss  3.72 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  29 | time: 143.57s | training loss  3.66 |
    | end of validation epoch  29 | time: 121.04s | validation loss  3.11 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 29 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 30
| epoch  30 |   100/  475 batches | ms/batch 398.79 | loss  3.82 |
| epoch  30 |   200/  475 batches | ms/batch 349.87 | loss  3.54 |
| epoch  30 |   300/  475 batches | ms/batch 327.62 | loss  3.41 |
| epoch  30 |   400/  475 batches | ms/batch 317.01 | loss  3.58 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  30 | time: 148.15s | training loss  3.65 |
    | end of validation epoch  30 | time: 123.10s | validation loss  3.03 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 30 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 31
| epoch  31 |   100/  475 batches | ms/batch 353.77 | loss  3.99 |
| epoch  31 |   200/  475 batches | ms/batch 315.36 | loss  3.57 |
| epoch  31 |   300/  475 batches | ms/batch 304.81 | loss  3.77 |
| epoch  31 |   400/  475 batches | ms/batch 298.70 | loss  3.41 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  31 | time: 142.90s | training loss  3.62 |
    | end of validation epoch  31 | time: 120.31s | validation loss  2.96 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 31 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 32
| epoch  32 |   100/  475 batches | ms/batch 391.61 | loss  3.62 |
| epoch  32 |   200/  475 batches | ms/batch 337.96 | loss  3.67 |
| epoch  32 |   300/  475 batches | ms/batch 322.63 | loss  3.62 |
| epoch  32 |   400/  475 batches | ms/batch 313.30 | loss  3.55 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  32 | time: 147.73s | training loss  3.59 |
    | end of validation epoch  32 | time: 114.22s | validation loss  3.01 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 32 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 33
| epoch  33 |   100/  475 batches | ms/batch 310.31 | loss  3.59 |
| epoch  33 |   200/  475 batches | ms/batch 294.59 | loss  3.60 |
| epoch  33 |   300/  475 batches | ms/batch 291.92 | loss  3.45 |
| epoch  33 |   400/  475 batches | ms/batch 291.89 | loss  3.33 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  33 | time: 137.42s | training loss  3.58 |
    | end of validation epoch  33 | time: 121.79s | validation loss  2.96 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 33 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 34
| epoch  34 |   100/  475 batches | ms/batch 355.86 | loss  3.30 |
| epoch  34 |   200/  475 batches | ms/batch 320.78 | loss  3.86 |
| epoch  34 |   300/  475 batches | ms/batch 307.52 | loss  3.56 |
| epoch  34 |   400/  475 batches | ms/batch 300.48 | loss  3.22 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  34 | time: 143.49s | training loss  3.57 |
    | end of validation epoch  34 | time: 119.28s | validation loss  2.91 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 34 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 35
| epoch  35 |   100/  475 batches | ms/batch 374.22 | loss  3.31 |
| epoch  35 |   200/  475 batches | ms/batch 333.59 | loss  3.19 |
| epoch  35 |   300/  475 batches | ms/batch 315.12 | loss  4.16 |
| epoch  35 |   400/  475 batches | ms/batch 309.96 | loss  3.45 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  35 | time: 146.85s | training loss  3.54 |
    | end of validation epoch  35 | time: 116.02s | validation loss  2.91 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 35 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 36
| epoch  36 |   100/  475 batches | ms/batch 348.22 | loss  3.67 |
| epoch  36 |   200/  475 batches | ms/batch 313.63 | loss  3.43 |
| epoch  36 |   300/  475 batches | ms/batch 304.38 | loss  3.29 |
| epoch  36 |   400/  475 batches | ms/batch 305.69 | loss  3.60 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  36 | time: 142.46s | training loss  3.53 |
    | end of validation epoch  36 | time: 119.27s | validation loss  2.97 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 36 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 37
| epoch  37 |   100/  475 batches | ms/batch 379.37 | loss  3.42 |
| epoch  37 |   200/  475 batches | ms/batch 339.17 | loss  3.63 |
| epoch  37 |   300/  475 batches | ms/batch 324.17 | loss  3.23 |
| epoch  37 |   400/  475 batches | ms/batch 314.24 | loss  3.67 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  37 | time: 145.78s | training loss  3.52 |
    | end of validation epoch  37 | time: 113.47s | validation loss  2.85 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 37 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 38
| epoch  38 |   100/  475 batches | ms/batch 286.76 | loss  3.78 |
| epoch  38 |   200/  475 batches | ms/batch 287.19 | loss  3.47 |
| epoch  38 |   300/  475 batches | ms/batch 288.66 | loss  3.50 |
| epoch  38 |   400/  475 batches | ms/batch 287.19 | loss  3.43 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  38 | time: 139.09s | training loss  3.50 |
    | end of validation epoch  38 | time: 117.94s | validation loss  2.89 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 38 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 39
| epoch  39 |   100/  475 batches | ms/batch 317.11 | loss  3.58 |
| epoch  39 |   200/  475 batches | ms/batch 304.50 | loss  3.33 |
| epoch  39 |   300/  475 batches | ms/batch 299.69 | loss  3.31 |
| epoch  39 |   400/  475 batches | ms/batch 294.85 | loss  3.20 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  39 | time: 139.51s | training loss  3.48 |
    | end of validation epoch  39 | time: 119.05s | validation loss  2.87 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 39 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 40
| epoch  40 |   100/  475 batches | ms/batch 346.32 | loss  3.30 |
| epoch  40 |   200/  475 batches | ms/batch 331.41 | loss  3.81 |
| epoch  40 |   300/  475 batches | ms/batch 316.04 | loss  3.47 |
| epoch  40 |   400/  475 batches | ms/batch 309.92 | loss  3.39 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  40 | time: 144.81s | training loss  3.47 |
    | end of validation epoch  40 | time: 120.21s | validation loss  2.88 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 40 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 41
| epoch  41 |   100/  475 batches | ms/batch 331.72 | loss  3.26 |
| epoch  41 |   200/  475 batches | ms/batch 305.38 | loss  3.29 |
| epoch  41 |   300/  475 batches | ms/batch 299.59 | loss  3.50 |
| epoch  41 |   400/  475 batches | ms/batch 298.94 | loss  3.56 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  41 | time: 140.79s | training loss  3.47 |
    | end of validation epoch  41 | time: 117.66s | validation loss  2.85 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 41 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 42
| epoch  42 |   100/  475 batches | ms/batch 372.32 | loss  3.69 |
| epoch  42 |   200/  475 batches | ms/batch 328.26 | loss  3.25 |
| epoch  42 |   300/  475 batches | ms/batch 315.04 | loss  3.30 |
| epoch  42 |   400/  475 batches | ms/batch 308.99 | loss  3.20 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  42 | time: 144.50s | training loss  3.43 |
    | end of validation epoch  42 | time: 119.16s | validation loss  2.85 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 42 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 43
| epoch  43 |   100/  475 batches | ms/batch 308.94 | loss  3.56 |
| epoch  43 |   200/  475 batches | ms/batch 300.55 | loss  3.21 |
| epoch  43 |   300/  475 batches | ms/batch 291.57 | loss  3.90 |
| epoch  43 |   400/  475 batches | ms/batch 291.11 | loss  3.49 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  43 | time: 137.30s | training loss  3.44 |
    | end of validation epoch  43 | time: 117.06s | validation loss  2.86 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 43 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786]
this is epoch 44
| epoch  44 |   100/  475 batches | ms/batch 334.04 | loss  3.53 |
| epoch  44 |   200/  475 batches | ms/batch 304.91 | loss  3.37 |
| epoch  44 |   300/  475 batches | ms/batch 299.38 | loss  3.87 |
| epoch  44 |   400/  475 batches | ms/batch 299.57 | loss  3.16 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  44 | time: 141.99s | training loss  3.42 |
    | end of validation epoch  44 | time: 118.81s | validation loss  2.85 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 44 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 45
| epoch  45 |   100/  475 batches | ms/batch 354.63 | loss  3.70 |
| epoch  45 |   200/  475 batches | ms/batch 337.39 | loss  3.17 |
| epoch  45 |   300/  475 batches | ms/batch 317.58 | loss  3.88 |
| epoch  45 |   400/  475 batches | ms/batch 309.97 | loss  3.63 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  45 | time: 145.27s | training loss  3.39 |
    | end of validation epoch  45 | time: 122.87s | validation loss  2.81 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 45 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 46
| epoch  46 |   100/  475 batches | ms/batch 374.77 | loss  3.31 |
| epoch  46 |   200/  475 batches | ms/batch 329.55 | loss  3.88 |
| epoch  46 |   300/  475 batches | ms/batch 320.45 | loss  3.38 |
| epoch  46 |   400/  475 batches | ms/batch 311.73 | loss  3.40 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  46 | time: 147.08s | training loss  3.39 |
    | end of validation epoch  46 | time: 115.72s | validation loss  2.79 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 46 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 47
| epoch  47 |   100/  475 batches | ms/batch 333.11 | loss  3.37 |
| epoch  47 |   200/  475 batches | ms/batch 322.02 | loss  3.11 |
| epoch  47 |   300/  475 batches | ms/batch 305.96 | loss  3.18 |
| epoch  47 |   400/  475 batches | ms/batch 298.07 | loss  3.25 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  47 | time: 139.71s | training loss  3.39 |
    | end of validation epoch  47 | time: 116.46s | validation loss  2.78 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 47 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 48
| epoch  48 |   100/  475 batches | ms/batch 351.67 | loss  3.63 |
| epoch  48 |   200/  475 batches | ms/batch 313.10 | loss  3.43 |
| epoch  48 |   300/  475 batches | ms/batch 299.28 | loss  3.79 |
| epoch  48 |   400/  475 batches | ms/batch 300.88 | loss  3.36 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  48 | time: 141.34s | training loss  3.37 |
    | end of validation epoch  48 | time: 123.57s | validation loss  2.78 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 48 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 49
| epoch  49 |   100/  475 batches | ms/batch 404.31 | loss  3.33 |
| epoch  49 |   200/  475 batches | ms/batch 383.60 | loss  3.12 |
| epoch  49 |   300/  475 batches | ms/batch 352.80 | loss  3.58 |
| epoch  49 |   400/  475 batches | ms/batch 333.85 | loss  3.07 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  49 | time: 156.77s | training loss  3.34 |
    | end of validation epoch  49 | time: 120.51s | validation loss  2.77 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 49 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 50
| epoch  50 |   100/  475 batches | ms/batch 424.31 | loss  3.18 |
| epoch  50 |   200/  475 batches | ms/batch 379.34 | loss  3.49 |
| epoch  50 |   300/  475 batches | ms/batch 355.37 | loss  3.03 |
| epoch  50 |   400/  475 batches | ms/batch 337.43 | loss  3.16 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  50 | time: 158.03s | training loss  3.35 |
    | end of validation epoch  50 | time: 119.19s | validation loss  2.75 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 50 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007]
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 51
| epoch  51 |   100/  475 batches | ms/batch 373.57 | loss  2.93 |
| epoch  51 |   200/  475 batches | ms/batch 327.44 | loss  3.62 |
| epoch  51 |   300/  475 batches | ms/batch 315.19 | loss  3.45 |
| epoch  51 |   400/  475 batches | ms/batch 304.92 | loss  3.26 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  51 | time: 144.19s | training loss  3.33 |
    | end of validation epoch  51 | time: 119.04s | validation loss  2.76 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 51 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 52
| epoch  52 |   100/  475 batches | ms/batch 417.02 | loss  3.28 |
| epoch  52 |   200/  475 batches | ms/batch 349.51 | loss  3.13 |
| epoch  52 |   300/  475 batches | ms/batch 324.25 | loss  3.20 |
| epoch  52 |   400/  475 batches | ms/batch 311.22 | loss  3.60 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  52 | time: 145.43s | training loss  3.33 |
    | end of validation epoch  52 | time: 119.22s | validation loss  2.74 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 52 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 53
| epoch  53 |   100/  475 batches | ms/batch 330.14 | loss  3.05 |
| epoch  53 |   200/  475 batches | ms/batch 323.39 | loss  3.50 |
| epoch  53 |   300/  475 batches | ms/batch 306.53 | loss  4.11 |
| epoch  53 |   400/  475 batches | ms/batch 306.58 | loss  3.44 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  53 | time: 144.64s | training loss  3.32 |
    | end of validation epoch  53 | time: 122.13s | validation loss  2.74 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 53 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 54
| epoch  54 |   100/  475 batches | ms/batch 410.54 | loss  3.21 |
| epoch  54 |   200/  475 batches | ms/batch 350.55 | loss  3.28 |
| epoch  54 |   300/  475 batches | ms/batch 330.64 | loss  3.46 |
| epoch  54 |   400/  475 batches | ms/batch 321.23 | loss  3.35 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  54 | time: 149.48s | training loss  3.32 |
    | end of validation epoch  54 | time: 129.73s | validation loss  2.76 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 54 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 55
| epoch  55 |   100/  475 batches | ms/batch 376.76 | loss  3.06 |
| epoch  55 |   200/  475 batches | ms/batch 330.50 | loss  3.12 |
| epoch  55 |   300/  475 batches | ms/batch 311.86 | loss  3.16 |
| epoch  55 |   400/  475 batches | ms/batch 306.46 | loss  3.42 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  55 | time: 145.26s | training loss  3.28 |
    | end of validation epoch  55 | time: 118.92s | validation loss  2.68 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 55 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 56
| epoch  56 |   100/  475 batches | ms/batch 328.60 | loss  2.85 |
| epoch  56 |   200/  475 batches | ms/batch 310.29 | loss  3.53 |
| epoch  56 |   300/  475 batches | ms/batch 301.32 | loss  2.91 |
| epoch  56 |   400/  475 batches | ms/batch 297.57 | loss  3.61 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  56 | time: 141.14s | training loss  3.28 |
    | end of validation epoch  56 | time: 120.36s | validation loss  2.74 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 56 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 57
| epoch  57 |   100/  475 batches | ms/batch 323.76 | loss  3.21 |
| epoch  57 |   200/  475 batches | ms/batch 297.52 | loss  3.55 |
| epoch  57 |   300/  475 batches | ms/batch 290.20 | loss  3.59 |
| epoch  57 |   400/  475 batches | ms/batch 293.45 | loss  3.30 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  57 | time: 138.12s | training loss  3.28 |
    | end of validation epoch  57 | time: 117.21s | validation loss  2.70 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 57 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993]
this is epoch 58
| epoch  58 |   100/  475 batches | ms/batch 341.81 | loss  2.93 |
| epoch  58 |   200/  475 batches | ms/batch 303.50 | loss  3.46 |
| epoch  58 |   300/  475 batches | ms/batch 303.12 | loss  3.40 |
| epoch  58 |   400/  475 batches | ms/batch 300.09 | loss  3.15 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  58 | time: 141.15s | training loss  3.28 |
    | end of validation epoch  58 | time: 123.93s | validation loss  2.70 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 58 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984]
this is epoch 59
| epoch  59 |   100/  475 batches | ms/batch 414.19 | loss  2.89 |
| epoch  59 |   200/  475 batches | ms/batch 350.20 | loss  3.26 |
| epoch  59 |   300/  475 batches | ms/batch 336.21 | loss  2.84 |
| epoch  59 |   400/  475 batches | ms/batch 324.09 | loss  3.47 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  59 | time: 152.58s | training loss  3.26 |
    | end of validation epoch  59 | time: 122.07s | validation loss  2.67 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 59 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 60
| epoch  60 |   100/  475 batches | ms/batch 341.76 | loss  3.24 |
| epoch  60 |   200/  475 batches | ms/batch 320.00 | loss  3.17 |
| epoch  60 |   300/  475 batches | ms/batch 307.69 | loss  3.42 |
| epoch  60 |   400/  475 batches | ms/batch 303.33 | loss  3.86 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  60 | time: 142.12s | training loss  3.24 |
    | end of validation epoch  60 | time: 122.13s | validation loss  2.66 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 60 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 61
| epoch  61 |   100/  475 batches | ms/batch 346.83 | loss  3.14 |
| epoch  61 |   200/  475 batches | ms/batch 317.59 | loss  3.47 |
| epoch  61 |   300/  475 batches | ms/batch 306.37 | loss  3.15 |
| epoch  61 |   400/  475 batches | ms/batch 299.12 | loss  3.77 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  61 | time: 141.00s | training loss  3.23 |
    | end of validation epoch  61 | time: 118.52s | validation loss  2.66 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 61 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 62
| epoch  62 |   100/  475 batches | ms/batch 313.57 | loss  3.44 |
| epoch  62 |   200/  475 batches | ms/batch 296.01 | loss  3.55 |
| epoch  62 |   300/  475 batches | ms/batch 288.65 | loss  3.66 |
| epoch  62 |   400/  475 batches | ms/batch 292.59 | loss  3.15 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  62 | time: 137.53s | training loss  3.23 |
    | end of validation epoch  62 | time: 116.23s | validation loss  2.69 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 62 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 63
| epoch  63 |   100/  475 batches | ms/batch 334.95 | loss  3.35 |
| epoch  63 |   200/  475 batches | ms/batch 320.50 | loss  2.91 |
| epoch  63 |   300/  475 batches | ms/batch 308.58 | loss  3.15 |
| epoch  63 |   400/  475 batches | ms/batch 308.40 | loss  2.93 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  63 | time: 144.64s | training loss  3.22 |
    | end of validation epoch  63 | time: 118.20s | validation loss  2.65 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 63 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 64
| epoch  64 |   100/  475 batches | ms/batch 337.09 | loss  3.06 |
| epoch  64 |   200/  475 batches | ms/batch 313.38 | loss  3.20 |
| epoch  64 |   300/  475 batches | ms/batch 306.25 | loss  3.49 |
| epoch  64 |   400/  475 batches | ms/batch 299.56 | loss  3.38 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  64 | time: 140.80s | training loss  3.21 |
    | end of validation epoch  64 | time: 119.60s | validation loss  2.65 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 64 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 65
| epoch  65 |   100/  475 batches | ms/batch 338.86 | loss  3.23 |
| epoch  65 |   200/  475 batches | ms/batch 309.16 | loss  3.20 |
| epoch  65 |   300/  475 batches | ms/batch 303.49 | loss  2.91 |
| epoch  65 |   400/  475 batches | ms/batch 300.75 | loss  3.05 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  65 | time: 143.97s | training loss  3.21 |
    | end of validation epoch  65 | time: 122.74s | validation loss  2.64 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 65 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 66
| epoch  66 |   100/  475 batches | ms/batch 337.25 | loss  3.27 |
| epoch  66 |   200/  475 batches | ms/batch 308.27 | loss  3.26 |
| epoch  66 |   300/  475 batches | ms/batch 304.47 | loss  3.08 |
| epoch  66 |   400/  475 batches | ms/batch 296.29 | loss  3.21 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  66 | time: 141.64s | training loss  3.21 |
    | end of validation epoch  66 | time: 116.19s | validation loss  2.63 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 66 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 67
| epoch  67 |   100/  475 batches | ms/batch 326.58 | loss  3.20 |
| epoch  67 |   200/  475 batches | ms/batch 311.03 | loss  3.10 |
| epoch  67 |   300/  475 batches | ms/batch 299.78 | loss  3.13 |
| epoch  67 |   400/  475 batches | ms/batch 297.90 | loss  3.24 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  67 | time: 141.28s | training loss  3.20 |
    | end of validation epoch  67 | time: 122.41s | validation loss  2.67 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 67 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 68
| epoch  68 |   100/  475 batches | ms/batch 420.17 | loss  3.70 |
| epoch  68 |   200/  475 batches | ms/batch 354.63 | loss  3.15 |
| epoch  68 |   300/  475 batches | ms/batch 330.85 | loss  2.84 |
| epoch  68 |   400/  475 batches | ms/batch 319.34 | loss  2.90 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  68 | time: 151.76s | training loss  3.18 |
    | end of validation epoch  68 | time: 120.29s | validation loss  2.63 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 68 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 69
| epoch  69 |   100/  475 batches | ms/batch 342.06 | loss  2.78 |
| epoch  69 |   200/  475 batches | ms/batch 312.80 | loss  2.98 |
| epoch  69 |   300/  475 batches | ms/batch 303.95 | loss  3.05 |
| epoch  69 |   400/  475 batches | ms/batch 301.83 | loss  3.16 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  69 | time: 141.73s | training loss  3.17 |
    | end of validation epoch  69 | time: 119.45s | validation loss  2.62 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 69 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 70
| epoch  70 |   100/  475 batches | ms/batch 322.96 | loss  3.31 |
| epoch  70 |   200/  475 batches | ms/batch 301.86 | loss  3.47 |
| epoch  70 |   300/  475 batches | ms/batch 302.16 | loss  3.54 |
| epoch  70 |   400/  475 batches | ms/batch 297.67 | loss  3.34 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  70 | time: 140.76s | training loss  3.19 |
    | end of validation epoch  70 | time: 117.57s | validation loss  2.62 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 70 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977]
this is epoch 71
| epoch  71 |   100/  475 batches | ms/batch 368.78 | loss  3.43 |
| epoch  71 |   200/  475 batches | ms/batch 328.26 | loss  2.91 |
| epoch  71 |   300/  475 batches | ms/batch 314.73 | loss  3.17 |
| epoch  71 |   400/  475 batches | ms/batch 306.85 | loss  2.92 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  71 | time: 143.92s | training loss  3.16 |
    | end of validation epoch  71 | time: 115.19s | validation loss  2.62 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 71 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 72
| epoch  72 |   100/  475 batches | ms/batch 317.40 | loss  2.90 |
| epoch  72 |   200/  475 batches | ms/batch 295.33 | loss  2.94 |
| epoch  72 |   300/  475 batches | ms/batch 292.20 | loss  3.61 |
| epoch  72 |   400/  475 batches | ms/batch 288.13 | loss  2.78 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  72 | time: 136.83s | training loss  3.16 |
    | end of validation epoch  72 | time: 115.93s | validation loss  2.59 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 72 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 73
| epoch  73 |   100/  475 batches | ms/batch 334.26 | loss  3.07 |
| epoch  73 |   200/  475 batches | ms/batch 310.69 | loss  3.05 |
| epoch  73 |   300/  475 batches | ms/batch 306.97 | loss  3.24 |
| epoch  73 |   400/  475 batches | ms/batch 303.09 | loss  3.19 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  73 | time: 143.51s | training loss  3.14 |
    | end of validation epoch  73 | time: 120.48s | validation loss  2.57 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 73 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 74
| epoch  74 |   100/  475 batches | ms/batch 337.25 | loss  3.28 |
| epoch  74 |   200/  475 batches | ms/batch 318.33 | loss  3.02 |
| epoch  74 |   300/  475 batches | ms/batch 304.83 | loss  3.19 |
| epoch  74 |   400/  475 batches | ms/batch 300.37 | loss  2.84 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  74 | time: 144.83s | training loss  3.14 |
    | end of validation epoch  74 | time: 117.56s | validation loss  2.57 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 74 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 75
| epoch  75 |   100/  475 batches | ms/batch 324.23 | loss  3.53 |
| epoch  75 |   200/  475 batches | ms/batch 301.53 | loss  2.85 |
| epoch  75 |   300/  475 batches | ms/batch 295.64 | loss  2.68 |
| epoch  75 |   400/  475 batches | ms/batch 295.77 | loss  3.11 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  75 | time: 139.88s | training loss  3.14 |
    | end of validation epoch  75 | time: 118.54s | validation loss  2.60 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 75 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 76
| epoch  76 |   100/  475 batches | ms/batch 346.89 | loss  3.36 |
| epoch  76 |   200/  475 batches | ms/batch 315.62 | loss  2.93 |
| epoch  76 |   300/  475 batches | ms/batch 302.03 | loss  2.76 |
| epoch  76 |   400/  475 batches | ms/batch 308.24 | loss  3.28 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  76 | time: 144.80s | training loss  3.13 |
    | end of validation epoch  76 | time: 113.51s | validation loss  2.60 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 76 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 77
| epoch  77 |   100/  475 batches | ms/batch 318.26 | loss  3.21 |
| epoch  77 |   200/  475 batches | ms/batch 295.90 | loss  3.03 |
| epoch  77 |   300/  475 batches | ms/batch 295.89 | loss  3.00 |
| epoch  77 |   400/  475 batches | ms/batch 291.09 | loss  3.11 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  77 | time: 137.39s | training loss  3.11 |
    | end of validation epoch  77 | time: 116.05s | validation loss  2.59 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 77 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 78
| epoch  78 |   100/  475 batches | ms/batch 345.88 | loss  2.95 |
| epoch  78 |   200/  475 batches | ms/batch 334.07 | loss  3.45 |
| epoch  78 |   300/  475 batches | ms/batch 329.74 | loss  3.01 |
| epoch  78 |   400/  475 batches | ms/batch 321.29 | loss  3.09 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  78 | time: 147.77s | training loss  3.11 |
    | end of validation epoch  78 | time: 118.83s | validation loss  2.60 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 78 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592]
this is epoch 79
| epoch  79 |   100/  475 batches | ms/batch 392.35 | loss  3.23 |
| epoch  79 |   200/  475 batches | ms/batch 337.60 | loss  3.56 |
| epoch  79 |   300/  475 batches | ms/batch 326.32 | loss  3.36 |
| epoch  79 |   400/  475 batches | ms/batch 321.03 | loss  2.94 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  79 | time: 150.02s | training loss  3.10 |
    | end of validation epoch  79 | time: 119.22s | validation loss  2.64 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 79 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 80
| epoch  80 |   100/  475 batches | ms/batch 331.16 | loss  3.20 |
| epoch  80 |   200/  475 batches | ms/batch 304.20 | loss  2.91 |
| epoch  80 |   300/  475 batches | ms/batch 301.29 | loss  3.05 |
| epoch  80 |   400/  475 batches | ms/batch 296.77 | loss  2.91 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  80 | time: 139.92s | training loss  3.08 |
    | end of validation epoch  80 | time: 119.70s | validation loss  2.60 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 80 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944, 3.0800660670431035] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788, 2.604436765197946]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 81
| epoch  81 |   100/  475 batches | ms/batch 334.80 | loss  2.96 |
| epoch  81 |   200/  475 batches | ms/batch 309.61 | loss  2.95 |
| epoch  81 |   300/  475 batches | ms/batch 310.97 | loss  3.06 |
| epoch  81 |   400/  475 batches | ms/batch 305.07 | loss  2.90 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  81 | time: 142.87s | training loss  3.10 |
    | end of validation epoch  81 | time: 114.74s | validation loss  2.58 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 81 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944, 3.0800660670431035, 3.096311530063027] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788, 2.604436765197946, 2.5753227782850505]
this is epoch 82
| epoch  82 |   100/  475 batches | ms/batch 350.10 | loss  3.06 |
| epoch  82 |   200/  475 batches | ms/batch 310.65 | loss  3.10 |
| epoch  82 |   300/  475 batches | ms/batch 308.15 | loss  3.15 |
| epoch  82 |   400/  475 batches | ms/batch 300.29 | loss  3.28 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  82 | time: 142.46s | training loss  3.10 |
    | end of validation epoch  82 | time: 127.60s | validation loss  2.57 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 82 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944, 3.0800660670431035, 3.096311530063027, 3.0961043553603322] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788, 2.604436765197946, 2.5753227782850505, 2.56936549238798]
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 83
| epoch  83 |   100/  475 batches | ms/batch 389.12 | loss  2.84 |
| epoch  83 |   200/  475 batches | ms/batch 330.40 | loss  3.21 |
| epoch  83 |   300/  475 batches | ms/batch 321.97 | loss  3.23 |
| epoch  83 |   400/  475 batches | ms/batch 312.08 | loss  3.03 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  83 | time: 146.48s | training loss  3.08 |
    | end of validation epoch  83 | time: 117.17s | validation loss  2.59 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 83 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944, 3.0800660670431035, 3.096311530063027, 3.0961043553603322, 3.083634383051019] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788, 2.604436765197946, 2.5753227782850505, 2.56936549238798, 2.5874939585934165]
this is epoch 84
| epoch  84 |   100/  475 batches | ms/batch 329.28 | loss  3.35 |
| epoch  84 |   200/  475 batches | ms/batch 312.65 | loss  3.40 |
| epoch  84 |   300/  475 batches | ms/batch 304.22 | loss  3.19 |
| epoch  84 |   400/  475 batches | ms/batch 298.28 | loss  3.26 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  84 | time: 140.75s | training loss  3.07 |
    | end of validation epoch  84 | time: 119.47s | validation loss  2.56 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 84 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944, 3.0800660670431035, 3.096311530063027, 3.0961043553603322, 3.083634383051019, 3.0662982960751184] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788, 2.604436765197946, 2.5753227782850505, 2.56936549238798, 2.5874939585934165, 2.5575812123402826]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 85
| epoch  85 |   100/  475 batches | ms/batch 381.89 | loss  2.75 |
| epoch  85 |   200/  475 batches | ms/batch 338.68 | loss  2.83 |
| epoch  85 |   300/  475 batches | ms/batch 322.81 | loss  3.12 |
| epoch  85 |   400/  475 batches | ms/batch 313.38 | loss  3.00 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  85 | time: 147.25s | training loss  3.05 |
    | end of validation epoch  85 | time: 118.44s | validation loss  2.57 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 85 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944, 3.0800660670431035, 3.096311530063027, 3.0961043553603322, 3.083634383051019, 3.0662982960751184, 3.05160643878736] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788, 2.604436765197946, 2.5753227782850505, 2.56936549238798, 2.5874939585934165, 2.5575812123402826, 2.5696076325007846]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 86
| epoch  86 |   100/  475 batches | ms/batch 320.94 | loss  3.03 |
| epoch  86 |   200/  475 batches | ms/batch 317.47 | loss  2.95 |
| epoch  86 |   300/  475 batches | ms/batch 308.75 | loss  3.02 |
| epoch  86 |   400/  475 batches | ms/batch 302.10 | loss  2.75 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  86 | time: 141.96s | training loss  3.07 |
    | end of validation epoch  86 | time: 114.79s | validation loss  2.54 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 86 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944, 3.0800660670431035, 3.096311530063027, 3.0961043553603322, 3.083634383051019, 3.0662982960751184, 3.05160643878736, 3.071543692538613] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788, 2.604436765197946, 2.5753227782850505, 2.56936549238798, 2.5874939585934165, 2.5575812123402826, 2.5696076325007846, 2.537780809803169]
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 87
| epoch  87 |   100/  475 batches | ms/batch 379.60 | loss  3.28 |
| epoch  87 |   200/  475 batches | ms/batch 327.03 | loss  2.90 |
| epoch  87 |   300/  475 batches | ms/batch 320.50 | loss  2.67 |
| epoch  87 |   400/  475 batches | ms/batch 309.59 | loss  3.07 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  87 | time: 146.78s | training loss  3.06 |
    | end of validation epoch  87 | time: 121.90s | validation loss  2.56 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 87 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944, 3.0800660670431035, 3.096311530063027, 3.0961043553603322, 3.083634383051019, 3.0662982960751184, 3.05160643878736, 3.071543692538613, 3.057765464782715] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788, 2.604436765197946, 2.5753227782850505, 2.56936549238798, 2.5874939585934165, 2.5575812123402826, 2.5696076325007846, 2.537780809803169, 2.5613264186041698]
this is epoch 88
| epoch  88 |   100/  475 batches | ms/batch 374.41 | loss  2.83 |
| epoch  88 |   200/  475 batches | ms/batch 336.11 | loss  3.11 |
| epoch  88 |   300/  475 batches | ms/batch 320.59 | loss  2.88 |
| epoch  88 |   400/  475 batches | ms/batch 310.01 | loss  3.31 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  88 | time: 145.31s | training loss  3.04 |
    | end of validation epoch  88 | time: 118.97s | validation loss  2.56 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 88 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944, 3.0800660670431035, 3.096311530063027, 3.0961043553603322, 3.083634383051019, 3.0662982960751184, 3.05160643878736, 3.071543692538613, 3.057765464782715, 3.042721057691072] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788, 2.604436765197946, 2.5753227782850505, 2.56936549238798, 2.5874939585934165, 2.5575812123402826, 2.5696076325007846, 2.537780809803169, 2.5613264186041698, 2.5601631923883903]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 89
| epoch  89 |   100/  475 batches | ms/batch 364.81 | loss  3.25 |
| epoch  89 |   200/  475 batches | ms/batch 321.92 | loss  2.90 |
| epoch  89 |   300/  475 batches | ms/batch 310.54 | loss  3.36 |
| epoch  89 |   400/  475 batches | ms/batch 302.81 | loss  3.29 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  89 | time: 141.44s | training loss  3.04 |
    | end of validation epoch  89 | time: 120.28s | validation loss  2.59 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 89 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944, 3.0800660670431035, 3.096311530063027, 3.0961043553603322, 3.083634383051019, 3.0662982960751184, 3.05160643878736, 3.071543692538613, 3.057765464782715, 3.042721057691072, 3.0396080483888324] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788, 2.604436765197946, 2.5753227782850505, 2.56936549238798, 2.5874939585934165, 2.5575812123402826, 2.5696076325007846, 2.537780809803169, 2.5613264186041698, 2.5601631923883903, 2.5870675048908267]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 90
| epoch  90 |   100/  475 batches | ms/batch 368.85 | loss  2.91 |
| epoch  90 |   200/  475 batches | ms/batch 332.19 | loss  3.05 |
| epoch  90 |   300/  475 batches | ms/batch 314.74 | loss  3.11 |
| epoch  90 |   400/  475 batches | ms/batch 304.18 | loss  3.19 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  90 | time: 142.64s | training loss  3.02 |
    | end of validation epoch  90 | time: 124.00s | validation loss  2.58 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 90 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944, 3.0800660670431035, 3.096311530063027, 3.0961043553603322, 3.083634383051019, 3.0662982960751184, 3.05160643878736, 3.071543692538613, 3.057765464782715, 3.042721057691072, 3.0396080483888324, 3.0222931244498805] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788, 2.604436765197946, 2.5753227782850505, 2.56936549238798, 2.5874939585934165, 2.5575812123402826, 2.5696076325007846, 2.537780809803169, 2.5613264186041698, 2.5601631923883903, 2.5870675048908267, 2.5830854758495043]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 91
| epoch  91 |   100/  475 batches | ms/batch 349.75 | loss  2.79 |
| epoch  91 |   200/  475 batches | ms/batch 319.71 | loss  2.78 |
| epoch  91 |   300/  475 batches | ms/batch 305.93 | loss  3.50 |
| epoch  91 |   400/  475 batches | ms/batch 298.48 | loss  3.51 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  91 | time: 139.29s | training loss  3.04 |
    | end of validation epoch  91 | time: 115.11s | validation loss  2.57 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 91 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944, 3.0800660670431035, 3.096311530063027, 3.0961043553603322, 3.083634383051019, 3.0662982960751184, 3.05160643878736, 3.071543692538613, 3.057765464782715, 3.042721057691072, 3.0396080483888324, 3.0222931244498805, 3.0376178646087646] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788, 2.604436765197946, 2.5753227782850505, 2.56936549238798, 2.5874939585934165, 2.5575812123402826, 2.5696076325007846, 2.537780809803169, 2.5613264186041698, 2.5601631923883903, 2.5870675048908267, 2.5830854758495043, 2.572049643813061]
this is epoch 92
| epoch  92 |   100/  475 batches | ms/batch 321.03 | loss  3.14 |
| epoch  92 |   200/  475 batches | ms/batch 296.97 | loss  3.22 |
| epoch  92 |   300/  475 batches | ms/batch 297.79 | loss  3.17 |
| epoch  92 |   400/  475 batches | ms/batch 294.96 | loss  2.92 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  92 | time: 138.94s | training loss  3.01 |
    | end of validation epoch  92 | time: 115.96s | validation loss  2.58 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 92 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944, 3.0800660670431035, 3.096311530063027, 3.0961043553603322, 3.083634383051019, 3.0662982960751184, 3.05160643878736, 3.071543692538613, 3.057765464782715, 3.042721057691072, 3.0396080483888324, 3.0222931244498805, 3.0376178646087646, 3.0139505602184093] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788, 2.604436765197946, 2.5753227782850505, 2.56936549238798, 2.5874939585934165, 2.5575812123402826, 2.5696076325007846, 2.537780809803169, 2.5613264186041698, 2.5601631923883903, 2.5870675048908267, 2.5830854758495043, 2.572049643813061, 2.581188478389708]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 93
| epoch  93 |   100/  475 batches | ms/batch 365.43 | loss  3.00 |
| epoch  93 |   200/  475 batches | ms/batch 320.39 | loss  3.15 |
| epoch  93 |   300/  475 batches | ms/batch 310.56 | loss  2.98 |
| epoch  93 |   400/  475 batches | ms/batch 302.58 | loss  2.79 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  93 | time: 142.24s | training loss  3.02 |
    | end of validation epoch  93 | time: 122.81s | validation loss  2.58 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 93 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944, 3.0800660670431035, 3.096311530063027, 3.0961043553603322, 3.083634383051019, 3.0662982960751184, 3.05160643878736, 3.071543692538613, 3.057765464782715, 3.042721057691072, 3.0396080483888324, 3.0222931244498805, 3.0376178646087646, 3.0139505602184093, 3.0177387418245014] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788, 2.604436765197946, 2.5753227782850505, 2.56936549238798, 2.5874939585934165, 2.5575812123402826, 2.5696076325007846, 2.537780809803169, 2.5613264186041698, 2.5601631923883903, 2.5870675048908267, 2.5830854758495043, 2.572049643813061, 2.581188478389708, 2.5774965586782503]
this is epoch 94
| epoch  94 |   100/  475 batches | ms/batch 383.44 | loss  3.17 |
| epoch  94 |   200/  475 batches | ms/batch 329.90 | loss  2.85 |
| epoch  94 |   300/  475 batches | ms/batch 322.89 | loss  3.15 |
| epoch  94 |   400/  475 batches | ms/batch 318.52 | loss  3.17 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  94 | time: 150.09s | training loss  3.02 |
    | end of validation epoch  94 | time: 121.93s | validation loss  2.54 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 94 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944, 3.0800660670431035, 3.096311530063027, 3.0961043553603322, 3.083634383051019, 3.0662982960751184, 3.05160643878736, 3.071543692538613, 3.057765464782715, 3.042721057691072, 3.0396080483888324, 3.0222931244498805, 3.0376178646087646, 3.0139505602184093, 3.0177387418245014, 3.0174019351758457] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788, 2.604436765197946, 2.5753227782850505, 2.56936549238798, 2.5874939585934165, 2.5575812123402826, 2.5696076325007846, 2.537780809803169, 2.5613264186041698, 2.5601631923883903, 2.5870675048908267, 2.5830854758495043, 2.572049643813061, 2.581188478389708, 2.5774965586782503, 2.5403599298300863]
this is epoch 95
| epoch  95 |   100/  475 batches | ms/batch 367.47 | loss  2.89 |
| epoch  95 |   200/  475 batches | ms/batch 320.70 | loss  3.01 |
| epoch  95 |   300/  475 batches | ms/batch 313.05 | loss  2.59 |
| epoch  95 |   400/  475 batches | ms/batch 305.58 | loss  2.86 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  95 | time: 144.15s | training loss  3.01 |
    | end of validation epoch  95 | time: 121.74s | validation loss  2.56 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 95 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944, 3.0800660670431035, 3.096311530063027, 3.0961043553603322, 3.083634383051019, 3.0662982960751184, 3.05160643878736, 3.071543692538613, 3.057765464782715, 3.042721057691072, 3.0396080483888324, 3.0222931244498805, 3.0376178646087646, 3.0139505602184093, 3.0177387418245014, 3.0174019351758457, 3.0066128555097076] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788, 2.604436765197946, 2.5753227782850505, 2.56936549238798, 2.5874939585934165, 2.5575812123402826, 2.5696076325007846, 2.537780809803169, 2.5613264186041698, 2.5601631923883903, 2.5870675048908267, 2.5830854758495043, 2.572049643813061, 2.581188478389708, 2.5774965586782503, 2.5403599298300863, 2.5593204728695524]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 96
| epoch  96 |   100/  475 batches | ms/batch 348.81 | loss  2.75 |
| epoch  96 |   200/  475 batches | ms/batch 316.33 | loss  3.41 |
| epoch  96 |   300/  475 batches | ms/batch 311.64 | loss  3.21 |
| epoch  96 |   400/  475 batches | ms/batch 301.77 | loss  2.86 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  96 | time: 141.74s | training loss  2.99 |
    | end of validation epoch  96 | time: 114.39s | validation loss  2.57 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 96 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944, 3.0800660670431035, 3.096311530063027, 3.0961043553603322, 3.083634383051019, 3.0662982960751184, 3.05160643878736, 3.071543692538613, 3.057765464782715, 3.042721057691072, 3.0396080483888324, 3.0222931244498805, 3.0376178646087646, 3.0139505602184093, 3.0177387418245014, 3.0174019351758457, 3.0066128555097076, 2.993098136500308] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788, 2.604436765197946, 2.5753227782850505, 2.56936549238798, 2.5874939585934165, 2.5575812123402826, 2.5696076325007846, 2.537780809803169, 2.5613264186041698, 2.5601631923883903, 2.5870675048908267, 2.5830854758495043, 2.572049643813061, 2.581188478389708, 2.5774965586782503, 2.5403599298300863, 2.5593204728695524, 2.5688189368288055]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 97
| epoch  97 |   100/  475 batches | ms/batch 283.43 | loss  3.13 |
| epoch  97 |   200/  475 batches | ms/batch 296.38 | loss  2.63 |
| epoch  97 |   300/  475 batches | ms/batch 301.56 | loss  3.29 |
| epoch  97 |   400/  475 batches | ms/batch 293.93 | loss  2.95 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  97 | time: 143.27s | training loss  2.98 |
    | end of validation epoch  97 | time: 140.76s | validation loss  2.55 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 97 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944, 3.0800660670431035, 3.096311530063027, 3.0961043553603322, 3.083634383051019, 3.0662982960751184, 3.05160643878736, 3.071543692538613, 3.057765464782715, 3.042721057691072, 3.0396080483888324, 3.0222931244498805, 3.0376178646087646, 3.0139505602184093, 3.0177387418245014, 3.0174019351758457, 3.0066128555097076, 2.993098136500308, 2.976084472254703] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788, 2.604436765197946, 2.5753227782850505, 2.56936549238798, 2.5874939585934165, 2.5575812123402826, 2.5696076325007846, 2.537780809803169, 2.5613264186041698, 2.5601631923883903, 2.5870675048908267, 2.5830854758495043, 2.572049643813061, 2.581188478389708, 2.5774965586782503, 2.5403599298300863, 2.5593204728695524, 2.5688189368288055, 2.5513301306412]
 Best training model found.
---------------------------------------------------------------------------------------------------
this is epoch 98
| epoch  98 |   100/  475 batches | ms/batch 358.24 | loss  3.16 |
| epoch  98 |   200/  475 batches | ms/batch 327.61 | loss  3.10 |
| epoch  98 |   300/  475 batches | ms/batch 312.76 | loss  2.96 |
| epoch  98 |   400/  475 batches | ms/batch 309.89 | loss  2.53 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  98 | time: 145.48s | training loss  2.98 |
    | end of validation epoch  98 | time: 120.99s | validation loss  2.50 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 98 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944, 3.0800660670431035, 3.096311530063027, 3.0961043553603322, 3.083634383051019, 3.0662982960751184, 3.05160643878736, 3.071543692538613, 3.057765464782715, 3.042721057691072, 3.0396080483888324, 3.0222931244498805, 3.0376178646087646, 3.0139505602184093, 3.0177387418245014, 3.0174019351758457, 3.0066128555097076, 2.993098136500308, 2.976084472254703, 2.9798445310090718] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788, 2.604436765197946, 2.5753227782850505, 2.56936549238798, 2.5874939585934165, 2.5575812123402826, 2.5696076325007846, 2.537780809803169, 2.5613264186041698, 2.5601631923883903, 2.5870675048908267, 2.5830854758495043, 2.572049643813061, 2.581188478389708, 2.5774965586782503, 2.5403599298300863, 2.5593204728695524, 2.5688189368288055, 2.5513301306412, 2.499021905810893]
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
this is epoch 99
| epoch  99 |   100/  475 batches | ms/batch 385.87 | loss  2.72 |
| epoch  99 |   200/  475 batches | ms/batch 338.81 | loss  3.53 |
| epoch  99 |   300/  475 batches | ms/batch 332.50 | loss  2.75 |
| epoch  99 |   400/  475 batches | ms/batch 320.63 | loss  2.98 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  99 | time: 148.36s | training loss  2.97 |
    | end of validation epoch  99 | time: 119.38s | validation loss  2.49 |
---------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------
after epoch 99 training loss is  [5.9065556415758635, 5.608660655774568, 5.359002604233591, 5.158603111066316, 4.970516510009766, 4.8225389410320085, 4.697329559326172, 4.590462757411756, 4.488935344093725, 4.406004155309577, 4.359089741455882, 4.279619600898341, 4.214697429757369, 4.1569515554528484, 4.097097625732422, 4.052112278687327, 4.011443940714786, 3.9680456502814043, 3.939480195798372, 3.9045026678788033, 3.8571986876035993, 3.836000546907124, 3.8087272960261296, 3.7686009241405287, 3.7478814476414732, 3.7168934701618395, 3.7120338635695607, 3.687029081143831, 3.6559479929271497, 3.652223571978117, 3.617771667681242, 3.5859694651553506, 3.5762403869628905, 3.5738531860552336, 3.5365382560930754, 3.534147219406931, 3.5226205419239247, 3.5047278248636347, 3.483630377116956, 3.4731381300876016, 3.4679725079787405, 3.4326798459103234, 3.4368349597328587, 3.4211181936765973, 3.389438694903725, 3.3882228128533614, 3.3859205938640393, 3.3706652530870937, 3.3418321047331156, 3.3546996347527753, 3.334562148545918, 3.3279227382258365, 3.3208512973785402, 3.3171128378416364, 3.282350223942807, 3.276590236362658, 3.284481907392803, 3.279114088761179, 3.2620224375473827, 3.243756012163664, 3.2325415094275223, 3.2310619218725907, 3.2194585945731715, 3.2106238706488357, 3.2100890686637475, 3.2091570507852656, 3.201056393573159, 3.175654184943751, 3.1689660328312925, 3.1863307531256426, 3.162754867955258, 3.158737191651997, 3.1425241053731816, 3.139233832610281, 3.1374028351432397, 3.132187187797145, 3.107287903835899, 3.1078796236138593, 3.0982447689457944, 3.0800660670431035, 3.096311530063027, 3.0961043553603322, 3.083634383051019, 3.0662982960751184, 3.05160643878736, 3.071543692538613, 3.057765464782715, 3.042721057691072, 3.0396080483888324, 3.0222931244498805, 3.0376178646087646, 3.0139505602184093, 3.0177387418245014, 3.0174019351758457, 3.0066128555097076, 2.993098136500308, 2.976084472254703, 2.9798445310090718, 2.9749133958314595] validation loss is  [5.62185000571884, 5.345151797062209, 4.9904109850651075, 4.728680778952206, 4.526658863580527, 4.277827318976907, 4.1353976806672685, 4.058730880753333, 3.929129844954034, 3.819849937903781, 3.91542948794966, 3.694280047376617, 3.6109695354429614, 3.5566237513758554, 3.504500248852898, 3.4243727692035066, 3.3781759879168343, 3.36778136261371, 3.3679240972054103, 3.300606503206141, 3.2525166723908496, 3.23272194782225, 3.2058759196465756, 3.1395989766641823, 3.108966074070009, 3.122820846172942, 3.0411579268319264, 3.04811006834527, 3.108635265286229, 3.030235354639903, 2.962342642936386, 3.008574479768256, 2.9608081048276245, 2.9085571345160988, 2.9090722949564958, 2.9655680997031078, 2.8527027358527945, 2.887331511794018, 2.8675778773652407, 2.8765654123129965, 2.8515915029189167, 2.8454667139454046, 2.8563179188415786, 2.8475100292878994, 2.8127174036843434, 2.7921119297251984, 2.7820698113000693, 2.781577262557855, 2.7715489263294124, 2.749090465177007, 2.755047716012522, 2.740867933305372, 2.737092270570643, 2.7631938277172443, 2.6812928043493702, 2.744418312521542, 2.6996646247991993, 2.6950337506141984, 2.666287919052509, 2.662813781690197, 2.664696114403861, 2.6943992927294818, 2.6494690169807242, 2.6500613398912574, 2.635576612809125, 2.6345196221055103, 2.6672492668408307, 2.629587879701823, 2.6169768481695352, 2.6248468871877977, 2.6240147131831706, 2.5936289434673405, 2.572399111355052, 2.57151619125815, 2.6021852363057496, 2.601854167064699, 2.5898917102012313, 2.596471335707592, 2.6378750039749788, 2.604436765197946, 2.5753227782850505, 2.56936549238798, 2.5874939585934165, 2.5575812123402826, 2.5696076325007846, 2.537780809803169, 2.5613264186041698, 2.5601631923883903, 2.5870675048908267, 2.5830854758495043, 2.572049643813061, 2.581188478389708, 2.5774965586782503, 2.5403599298300863, 2.5593204728695524, 2.5688189368288055, 2.5513301306412, 2.499021905810893, 2.494442549072394]
 Best training model found.
---------------------------------------------------------------------------------------------------
 Best validation model found and saved.
---------------------------------------------------------------------------------------------------
